{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the following article is to get a step-by-step guide on how to use or build `lag transform` and `lags` using `Mlforecast`.\n",
    "\n",
    "During this walkthrough, we will become familiar with the main `MlForecast` class and some relevant methods such as `mlforecast.fit`, `mlforecast.predict` and `mlforecast.cross_validation` in other.\n",
    "\n",
    "Let's start!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "\n",
    "\n",
    "\n",
    "1.\t[Introduction](#1)\n",
    "2.\t[Lags y Lag transforms](#2)\n",
    "3.\t[Installing Mlforecast](#3)\n",
    "4.\t[Loading libraries and data](#4)\n",
    "5.\t[Explore Data with the plot method](#5)\n",
    "6.\t[Split the data into training and testing](#6)\n",
    "7.\t[Implementation of model with MLForecast](#7)\n",
    "8.  [References](#8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introduction** <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "Time series lags are powerful tools that allow you to analyze patterns, identify dependencies and build predictive models. They are especially useful for capturing the temporal structure of data and improving prediction ability in time series analysis.\n",
    "\n",
    "Lags in time series represent the time delays or lags used to analyze the relationship between past and future values of the series. They are essential for calculating autocorrelation and capturing temporal patterns in time series analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Lags and lags transforms** <a class=\"anchor\" id=\"2\"></a>\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "## **2.1 Lags**\n",
    "\n",
    "\n",
    "**Definition:** Given a time series $X_t$, where $t$ is the time index, the lag of order $k$, denoted as $X_{t-k}$, is defined as a lagged version of the original series $X_t $.\n",
    "\n",
    "Mathematically, the k-order lag is calculated as follows:\n",
    "\n",
    "$$X_{t-k} = X_t$$\n",
    "\n",
    "In this definition, $X_{t-k}$ represents the value of the time series $X_t$ lagged by $k$ time periods. That is, the value of the time series $t-k$ is taken and assigned as the value corresponding to lag $X_{t-k}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of time series, \"lags\" refer to the time delays or lags used to analyze the relationship between past and future values in the series. A lag is a measure of time that indicates how many previous periods are taken into account when analyzing the relationship between past and future values of a time series.\n",
    "\n",
    "When studying autocorrelation in a time series, it is common to use lags to calculate autocorrelation coefficients. The autocorrelation coefficient indicates the relationship between the past and future values of the series depending on the number of lags considered.\n",
    "\n",
    "Lags are used to examine autocorrelation in a time series, that is, the relationship or dependence between past and future values. By considering different lags, it is possible to evaluate how earlier values influence later values and whether there are recurring patterns or trends in the series.\n",
    "\n",
    "For example, if we have a monthly time series that records the monthly average total number of sunspots, and we are interested in analyzing the relationship between the current monthly average total sunspot number and the previous month's monthly average total sunspot number, we would be using a lag of 1 month. This implies that we are shifting the values of the series one month back to compare them with the current values.\n",
    "\n",
    "Lags can be used to calculate autocorrelation, which is a measure of the similarity between values in a time series at different periods. Autocorrelation coefficients indicate the strength and direction of the relationship between lags and current values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Lag Properties**\n",
    "\n",
    "Lags have several important properties in time series that can be useful for data analysis and modeling. Below are some of the most relevant properties:\n",
    "\n",
    "1. Autocorrelation: Lags allow you to calculate the autocorrelation of a time series, that is, the correlation between the past and present values of the series. Autocorrelation can help identify repetitive patterns and stationarity in data.\n",
    "\n",
    "2. Prediction: Lags are commonly used to build time series prediction models. By including lags as predictor variables in a model, the dependence on past values in predicting future values can be captured.\n",
    "\n",
    "3. Seasonality: Lags can also reveal seasonal patterns in a time series. By looking at lags for previous seasonal periods (for example, monthly lags or quarterly lags), you can identify whether repetitive patterns exist at certain times of the year.\n",
    "\n",
    "4. Trend analysis: Lags can be useful to analyze the trend of a time series. By calculating lags of different orders, you can evaluate how past values affect the overall trend of the data.\n",
    "\n",
    "5. Dependency modeling: Lags allow you to capture dependencies between the past and present values of a time series. By including multiple lags in a model, complex relationships, such as lags in the response of one variable to another, can be detected and modeled.\n",
    "\n",
    "6. Elimination of autocorrelation: Lags can also be used to eliminate autocorrelation in a time series. By calculating the residuals after fitting a model with lags, one can evaluate whether any unexplained autocorrelation structure remains.\n",
    "\n",
    "In summary, time series lags are powerful tools that allow you to analyze patterns, identify dependencies and build predictive models. They are especially useful for capturing the temporal structure of data and improving prediction ability in time series analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Lag transforms**\n",
    "\n",
    "Lag transforms are defined as a dictionary where the keys are the lags and the values are lists of functions that transform an array. These must be [numba](http://numba.pydata.org) jitted functions (so that computing the features doesn’t become a bottleneck). There are some implemented in the [window-ops package](https://github.com/jmoralez/window_ops) but you can also implement your own.\n",
    "\n",
    "If the function takes two or more arguments you can either:\n",
    "\n",
    "- supply a tuple (tfm_func, arg1, arg2, …)\n",
    "- define a new function fixing the arguments\n",
    "\n",
    "### **Window ops**\n",
    "\n",
    "This library is intended to be used as an alternative to `pd.Series.rolling` and `pd.Series.expanding` to gain a speedup by using `numba` optimized functions operating on numpy arrays. There are also online classes for more efficient updates of window statistics.\n",
    "\n",
    "If you have an array for which you want to compute a window statistic and then keep updating it as more samples come in you can use the classes in the `window_ops.online` module. They all have a fit_transform method which take the array and return the transformations defined above but also have an update method that take a single value and return the new statistic.\n",
    "\n",
    "To use `window_ops` we must previously install it using pip:\n",
    "\n",
    "`pip install window-ops`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Window_ops` has many functions that are available to use, but there is also the freedom to build your own function if you require or need it, some of these functions are:\n",
    "\n",
    "| |window_ops|\tpandas|\n",
    "|-|----------|--------|\n",
    "|rolling_mean|\t0.03\t|0.43|\n",
    "|rolling_max|\t0.14\t|0.57|\n",
    "|rolling_min|\t0.14|\t0.58|\n",
    "|rolling_std|\t0.06|\t0.54|\n",
    "|expanding_mean|\t0.03|\t0.31|\n",
    "|expanding_max|\t0.05|\t0.76|\n",
    "|expanding_min|\t0.05|\t0.47|\n",
    "|expanding_std|\t0.09|\t0.41|\n",
    "|seasonal_rolling_mean|\t0.05|\t3.89|\n",
    "|seasonal_rolling_max|\t0.18|\t4.27|\n",
    "|seasonal_rolling_min|\t0.18|\t3.75|\n",
    "|seasonal_rolling_std|\t0.08|\t4.38|\n",
    "|seasonal_expanding_mean|\t0.04|\t3.18|\n",
    "|seasonal_expanding_max|\t0.06|\t3.29|\n",
    "|seasonal_expanding_min|\t0.06|\t3.28|\n",
    "|seasonal_expanding_std|\t0.12|\t3.89|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Installing Mlforecast** <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "* using pip:\n",
    "\n",
    "    - `pip install mlforecast`\n",
    "\n",
    "* Specific version\n",
    "\n",
    "    If you want a specific version you can include a filter, for example:\n",
    "\n",
    "    - `pip install \"mlforecast==0.3.0\"` to install the 0.3.0 version\n",
    "    - `pip install \"mlforecast<0.4.0\"` to install any version prior to 0.4.0\n",
    "\n",
    "* using with conda:\n",
    "\n",
    "    - `conda install -c conda-forge mlforecast`\n",
    "\n",
    "* Specific version\n",
    "\n",
    "    If you want a specific version you can include a filter, for example: \n",
    "\n",
    "    - `conda install -c conda-forge \"mlforecast==0.3.0\"` to install the 0.3.0 version\n",
    "    - `conda install -c conda-forge \"mlforecast<0.4.0\"` to install any version prior to 0.4.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Loading libraries and data** <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling and processing of Data\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Handling and processing of Data for Date (time)\n",
    "# ==============================================================================\n",
    "import datetime\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# \n",
    "# ==============================================================================\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose \n",
    "# \n",
    "# ==============================================================================\n",
    "from utilsforecast.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# \n",
    "# ==============================================================================\n",
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "from window_ops.ewm import ewm_mean\n",
    "from mlforecast.target_transforms import Differences\n",
    "\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "from mlforecast.utils import generate_daily_series, generate_prices_for_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.style.use('grayscale') # fivethirtyeight  grayscale  classic\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "dark_style = {\n",
    "    'figure.facecolor': '#008080',  # #212946\n",
    "    'axes.facecolor': '#008080',\n",
    "    'savefig.facecolor': '#008080',\n",
    "    'axes.grid': True,\n",
    "    'axes.grid.which': 'both',\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'grid.color': '#000000',  #2A3459\n",
    "    'grid.linewidth': '1',\n",
    "    'text.color': '0.9',\n",
    "    'axes.labelcolor': '0.9',\n",
    "    'xtick.color': '0.9',\n",
    "    'ytick.color': '0.9',\n",
    "    'font.size': 12 }\n",
    "plt.rcParams.update(dark_style)\n",
    "# Define the plot size\n",
    "# ==============================================================================\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18,7)\n",
    "\n",
    "# Hide warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>IPG3113N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>85.6945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>71.8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-03-01</td>\n",
       "      <td>66.0229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>64.5645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-05-01</td>\n",
       "      <td>65.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation_date  IPG3113N\n",
       "0       1972-01-01   85.6945\n",
       "1       1972-02-01   71.8200\n",
       "2       1972-03-01   66.0229\n",
       "3       1972-04-01   64.5645\n",
       "4       1972-05-01   65.0100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/Naren8520/Serie-de-tiempo-con-Machine-Learning/main/Data/candy_production.csv\",parse_dates=[\"observation_date\"])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to MlForecast is always a data frame in long format with three columns: unique_id, ds and y:\n",
    "\n",
    "* The `unique_id` (string, int or category) represents an identifier for the series.\n",
    "\n",
    "* The `ds` (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\n",
    "\n",
    "* The `y` (numeric) represents the measurement we wish to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>85.6945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>71.8200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-03-01</td>\n",
       "      <td>66.0229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>64.5645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-05-01</td>\n",
       "      <td>65.0100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds        y unique_id\n",
       "0 1972-01-01  85.6945         1\n",
       "1 1972-02-01  71.8200         1\n",
       "2 1972-03-01  66.0229         1\n",
       "3 1972-04-01  64.5645         1\n",
       "4 1972-05-01  65.0100         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"unique_id\"]=\"1\"\n",
    "df.columns=[\"ds\", \"y\", \"unique_id\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 548 entries, 0 to 547\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   ds         548 non-null    datetime64[ns]\n",
      " 1   y          548 non-null    float64       \n",
      " 2   unique_id  548 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 13.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Explore Data with the plot method** <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "Plot some series using the plot method from the StatsForecast class. This method prints 8 random series from the dataset and is useful for basic EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_series(df)\n",
    "fig.savefig('../figs/lag_transforms__eda.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__eda.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1 The Augmented Dickey-Fuller Test**\n",
    "An Augmented Dickey-Fuller (ADF) test is a type of statistical test that determines whether a unit root is present in time series data. Unit roots can cause unpredictable results in time series analysis. A null hypothesis is formed in the unit root test to determine how strongly time series data is affected by a trend. By accepting the null hypothesis, we accept the evidence that the time series data is not stationary. By rejecting the null hypothesis or accepting the alternative hypothesis, we accept the evidence that the time series data is generated by a stationary process. This process is also known as stationary trend. The values of the ADF test statistic are negative. Lower ADF values indicate a stronger rejection of the null hypothesis.\n",
    "\n",
    "Augmented Dickey-Fuller Test is a common statistical test used to test whether a given time series is stationary or not. We can achieve this by defining the null and alternate hypothesis.\n",
    "\n",
    "- Null Hypothesis: Time Series is non-stationary. It gives a time-dependent trend.\n",
    "- Alternate Hypothesis: Time Series is stationary. In another term, the series doesn’t depend on time.\n",
    "\n",
    "- ADF or t Statistic < critical values: Reject the null hypothesis, time series is stationary.\n",
    "- ADF or t Statistic > critical values: Failed to reject the null hypothesis, time series is non-stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_dickey_fuller_test(series , column_name):\n",
    "    print (f'Dickey-Fuller test results for columns: {column_name}')\n",
    "    dftest = adfuller(series, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','No Lags Used','Number of observations used'])\n",
    "    for key,value in dftest[4].items():\n",
    "       dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "    if dftest[1] <= 0.05:\n",
    "        print(\"Conclusion:====>\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"The data is stationary\")\n",
    "    else:\n",
    "        print(\"Conclusion:====>\")\n",
    "        print(\"The null hypothesis cannot be rejected\")\n",
    "        print(\"The data is not stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dickey-Fuller test results for columns: Candy Production\n",
      "Test Statistic                  -1.887050\n",
      "p-value                          0.338178\n",
      "No Lags Used                    14.000000\n",
      "Number of observations used    533.000000\n",
      "Critical Value (1%)             -3.442678\n",
      "Critical Value (5%)             -2.866978\n",
      "Critical Value (10%)            -2.569666\n",
      "dtype: float64\n",
      "Conclusion:====>\n",
      "The null hypothesis cannot be rejected\n",
      "The data is not stationary\n"
     ]
    }
   ],
   "source": [
    "augmented_dickey_fuller_test(df[\"y\"],\"Candy Production\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Autocorrelation plots**\n",
    "\n",
    "### **Autocorrelation Function**\n",
    "\n",
    "**Definition 1.** Let $\\{x_t;1 ≤ t ≤ n\\}$ be a time series sample of size n from $\\{X_t\\}$.\n",
    "1. $\\bar x = \\sum_{t=1}^n \\frac{x_t}{n}$ is called the sample mean of $\\{X_t\\}$.\n",
    "2. $c_k =\\sum_{t=1}^{n−k} (x_{t+k}- \\bar x)(x_t−\\bar x)/n$ is known as the sample autocovariance function of $\\{X_t\\}$.\n",
    "3. $r_k = c_k /c_0$ is said to be the sample autocorrelation function of $\\{X_t\\}$. \n",
    "\n",
    "Note the following remarks about this definition:\n",
    " \n",
    "* Like most literature, this guide uses ACF to denote the sample autocorrelation function as well as the autocorrelation function. What is denoted by ACF can easily be identified in context.\n",
    "\n",
    "* Clearly c0 is the sample variance of $\\{X_t\\}$. Besides, $r_0 = c_0/c_0 = 1$ and for any integer $k, |r_k| ≤ 1$.\n",
    "\n",
    "* When we compute the ACF of any sample series with a fixed length $n$, we cannot put too much confidence in the values of $r_k$ for large k’s, since fewer pairs of $(x_{t +k }, x_t )$ are available for calculating $r_k$ as $k$ is large. One rule of thumb is not to estimate $r_k$ for $k > n/3$, and another is $n ≥ 50, k ≤ n/4$. In any case, it is always a good idea to be careful.\n",
    "\n",
    "* We also compute the ACF of a nonstationary time series sample by Definition 1. In this case, however, the ACF or $r_k$ very slowly or hardly tapers off as $k$ increases.\n",
    "\n",
    "* Plotting the ACF $(r_k)$ against lag $k$ is easy but very helpful in analyzing time series sample. Such an ACF plot is known as a correlogram.\n",
    "\n",
    "* If $\\{X_t\\}$ is stationary with $E(X_t)=0$ and $\\rho_k =0$ for all $k \\neq 0$,thatis,itisa white noise series, then the sampling distribution of $r_k$ is asymptotically normal with the mean 0 and the variance of $1/n$. Hence, there is about 95% chance that $r_k$ falls in the interval $[−1.96/√n, 1.96/√n]$.\n",
    "\n",
    "Now we can give a summary that (1) if the time series plot of a time series clearly shows a trend or/and seasonality, it is surely nonstationary; (2) if the ACF $r_k$ very slowly or hardly tapers off as lag $k$ increases, the time series should also be nonstationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "plot_acf(df[\"y\"],  lags=30, ax=axs[0],color=\"fuchsia\")\n",
    "axs[0].set_title(\"Autocorrelation\");\n",
    "\n",
    "# Grafico\n",
    "plot_pacf(df[\"y\"],  lags=30, ax=axs[1],color=\"lime\")\n",
    "axs[1].set_title('Partial Autocorrelation')\n",
    "plt.savefig(\"../figs/lag_transforms__autocorrelation.png\")\n",
    "plt.close();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__autocorrelation.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.3 Decomposition of the time series**\n",
    "\n",
    "How to decompose a time series and why?\n",
    "\n",
    "In time series analysis to forecast new values, it is very important to know past data. More formally, we can say that it is very important to know the patterns that values follow over time. There can be many reasons that cause our forecast values to fall in the wrong direction. Basically, a time series consists of four components. The variation of those components causes the change in the pattern of the time series. These components are:\n",
    "\n",
    "* **Level:** This is the primary value that averages over time.\n",
    "* **Trend:** The trend is the value that causes increasing or decreasing patterns in a time series.\n",
    "* **Seasonality:** This is a cyclical event that occurs in a time series for a short time and causes short-term increasing or decreasing patterns in a time series.\n",
    "* **Residual/Noise:** These are the random variations in the time series.\n",
    "\n",
    "Combining these components over time leads to the formation of a time series. Most time series consist of level and noise/residual and trend or seasonality are optional values.\n",
    "\n",
    "If seasonality and trend are part of the time series, then there will be effects on the forecast value. As the pattern of the forecasted time series may be different from the previous time series.\n",
    "\n",
    "The combination of the components in time series can be of two types:\n",
    "* Additive\n",
    "* multiplicative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = seasonal_decompose(df[\"y\"], model = \"additive\", period=24).plot()\n",
    "a.savefig('../figs/lag_transforms__seasonal_decompose_aditive.png')\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__seasonal_decompose_aditive.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = seasonal_decompose(df[\"y\"], model = \"Multiplicative\", period=24).plot()\n",
    "m.savefig('../figs/lag_transforms__seasonal_decompose_multiplicative.png')\n",
    "plt.close();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__seasonal_decompose_multiplicative.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Modeling with MLForecast** <a class=\"anchor\" id=\"7\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Building Model**\n",
    "\n",
    "We define the model that we want to use, for our example we are going to use the `RandomForest() model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [RandomForestRegressor(n_estimators=1000,\n",
    "                               max_depth=2, \n",
    "                               random_state=1234,\n",
    "                               n_jobs=-1) ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the models by instantiating a new `MlForecast` object with the following parameters:\n",
    "\n",
    "* `models:` a list of models. Select the models you want from models and import them.\n",
    "\n",
    "* `freq:` a string indicating the frequency of the data. (See [panda’s available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).)\n",
    "\n",
    "* `lags:` Lags of the target to uses as feature.\n",
    "\n",
    "* `lag_transforms:` Mapping of target lags to their transformations.\n",
    "\n",
    "* `date_features:` Features computed from the dates. Can be `pandas` date attributes or functions that will take the dates as input.\n",
    "\n",
    "* `differences:` Differences to take of the target before computing the features. These are restored at the forecasting step.\n",
    "\n",
    "* `num_threads:` Number of threads to use when computing the features.\n",
    "\n",
    "* `target_transforms:` Transformations that will be applied to the target computing the features and restored after the forecasting step.\n",
    "\n",
    "Any settings are passed into the constructor. Then you call its fit method and pass in the historical data frame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Target transforms**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the series we are using is non-stationary, we are going to add a differential to eliminate a little of the trend that the series has, for this we are going to use the `target_transforms` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 target_transforms=[Differences([1])]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>-13.8745</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-03-01</td>\n",
       "      <td>-5.7971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>-1.4584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-05-01</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1972-06-01</td>\n",
       "      <td>2.6367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2.2043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>-5.5079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2.2813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>-1.6161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>11.4752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds        y unique_id\n",
       "1   1972-02-01 -13.8745         1\n",
       "2   1972-03-01  -5.7971         1\n",
       "3   1972-04-01  -1.4584         1\n",
       "4   1972-05-01   0.4455         1\n",
       "5   1972-06-01   2.6367         1\n",
       "..         ...      ...       ...\n",
       "543 2017-04-01   2.2043         1\n",
       "544 2017-05-01  -5.5079         1\n",
       "545 2017-06-01   2.2813         1\n",
       "546 2017-07-01  -1.6161         1\n",
       "547 2017-08-01  11.4752         1\n",
       "\n",
       "[547 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_series(prep)\n",
    "for ax in fig.get_axes():\n",
    "   ax.set_title(\"Differences\")\n",
    "fig.savefig('../figs/lag_transforms__plot_differences.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__plot_differences.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dickey-Fuller test results for columns: Candy Production\n",
      "Test Statistic                -6.119512e+00\n",
      "p-value                        8.925584e-08\n",
      "No Lags Used                   1.300000e+01\n",
      "Number of observations used    5.330000e+02\n",
      "Critical Value (1%)           -3.442678e+00\n",
      "Critical Value (5%)           -2.866978e+00\n",
      "Critical Value (10%)          -2.569666e+00\n",
      "dtype: float64\n",
      "Conclusion:====>\n",
      "Reject the null hypothesis\n",
      "The data is stationary\n"
     ]
    }
   ],
   "source": [
    "augmented_dickey_fuller_test(prep[\"y\"],\"Candy Production\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have eliminated the trend from our series, and with this we have achieved that our time series is now stationary.\n",
    "\n",
    "We can also add a `StandardScaler` that we have defined.\n",
    "\n",
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "The standard score of a sample $x$ is calculated as:\n",
    "\n",
    "$$z = (x - \\mu) / s$$\n",
    "\n",
    "where $\\mu$ is the mean of the training samples or zero if with_mean=False, and $s$ is the standard deviation of the training samples.\n",
    "\n",
    "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.\n",
    "\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.target_transforms import BaseTargetTransform\n",
    "\n",
    "class StandardScaler(BaseTargetTransform):\n",
    "    \"\"\"Standardizes the series by subtracting their mean and dividing by their standard deviation.\"\"\"\n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        self.norm_ = df.groupby(self.id_col)[self.target_col].agg(['mean', 'std'])\n",
    "        df = df.merge(self.norm_, on=self.id_col)\n",
    "        df[self.target_col] = (df[self.target_col] - df['mean']) / df['std']\n",
    "        df = df.drop(columns=['mean', 'std'])\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.merge(self.norm_, on=self.id_col)\n",
    "        for col in df.columns.drop([self.id_col, self.time_col, 'mean', 'std']):\n",
    "            df[col] = df[col] * df['std'] + df['mean']\n",
    "        df = df.drop(columns=['std', 'mean'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 target_transforms=[StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>-0.829119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>-1.597664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-03-01</td>\n",
       "      <td>-1.918781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>-1.999566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-05-01</td>\n",
       "      <td>-1.974888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.374802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.196072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.106552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.742194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y unique_id\n",
       "0   1972-01-01 -0.829119         1\n",
       "1   1972-02-01 -1.597664         1\n",
       "2   1972-03-01 -1.918781         1\n",
       "3   1972-04-01 -1.999566         1\n",
       "4   1972-05-01 -1.974888         1\n",
       "..         ...       ...       ...\n",
       "543 2017-04-01  0.374802         1\n",
       "544 2017-05-01  0.069705         1\n",
       "545 2017-06-01  0.196072         1\n",
       "546 2017-07-01  0.106552         1\n",
       "547 2017-08-01  0.742194         1\n",
       "\n",
       "[548 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_series(prep)\n",
    "for ax in fig.get_axes():\n",
    "   ax.set_title(\"StandardScaler\")\n",
    "fig.savefig('../figs/lag_transforms__plot_standardscaler.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__plot_standardscaler.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine both target transforms as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 target_transforms=[Differences([1]),StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972-02-01</td>\n",
       "      <td>-1.542319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-03-01</td>\n",
       "      <td>-0.647762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-05-01</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1972-06-01</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1.265114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y unique_id\n",
       "1   1972-02-01 -1.542319         1\n",
       "2   1972-03-01 -0.647762         1\n",
       "3   1972-04-01 -0.167258         1\n",
       "4   1972-05-01  0.043595         1\n",
       "5   1972-06-01  0.286266         1\n",
       "..         ...       ...       ...\n",
       "543 2017-04-01  0.238379         1\n",
       "544 2017-05-01 -0.615733         1\n",
       "545 2017-06-01  0.246907         1\n",
       "546 2017-07-01 -0.184723         1\n",
       "547 2017-08-01  1.265114         1\n",
       "\n",
       "[547 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_series(prep)\n",
    "for ax in fig.get_axes():\n",
    "   ax.set_title(\"Difference and StandardScaler\")\n",
    "fig.savefig('../figs/lag_transforms__plot_difference_standardscaler.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__plot_difference_standardscaler.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see now in the previous graph that we have a series that has no trend and is also standardized."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.3 Lags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 lags=[1],\n",
    "                 target_transforms=[Differences([1]),StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `MLForecast.preprocess` method to explore different transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972-03-01</td>\n",
       "      <td>-0.647762</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.542319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.647762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972-05-01</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.167258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1972-06-01</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1972-07-01</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.286266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds         y unique_id      lag1\n",
       "2 1972-03-01 -0.647762         1 -1.542319\n",
       "3 1972-04-01 -0.167258         1 -0.647762\n",
       "4 1972-05-01  0.043595         1 -0.167258\n",
       "5 1972-06-01  0.286266         1  0.043595\n",
       "6 1972-07-01  0.148883         1  0.286266"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have added $lags=1$ to our model. The `lags` parameter accepts a list of values that we can include in our model, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 lags=[1,2,4,6,8,10,12],\n",
    "                 target_transforms=[Differences([1]),StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag10</th>\n",
       "      <th>lag12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1973-02-01</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>-1.542319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1973-03-01</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.647762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1973-04-01</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>-0.167258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1973-05-01</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.043595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1973-06-01</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.286266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.484596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>-0.175886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.030006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.054814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1.265114</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.187678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y unique_id      lag1      lag2      lag4      lag6  \\\n",
       "13  1973-02-01 -1.559507         1 -1.630153  0.035355  3.525207  0.192950   \n",
       "14  1973-03-01 -0.853964         1 -1.559507 -1.630153 -0.153337  0.460418   \n",
       "15  1973-04-01  0.070407         1 -0.853964 -1.559507  0.035355  3.525207   \n",
       "16  1973-05-01  0.147488         1  0.070407 -0.853964 -1.630153 -0.153337   \n",
       "17  1973-06-01  0.346580         1  0.147488  0.070407 -1.559507  0.035355   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "543 2017-04-01  0.238379         1 -0.918485  0.437194 -0.048891  1.071958   \n",
       "544 2017-05-01 -0.615733         1  0.238379 -0.918485 -0.779530 -0.250176   \n",
       "545 2017-06-01  0.246907         1 -0.615733  0.238379  0.437194 -0.048891   \n",
       "546 2017-07-01 -0.184723         1  0.246907 -0.615733 -0.918485 -0.779530   \n",
       "547 2017-08-01  1.265114         1 -0.184723  0.246907  0.238379  0.437194   \n",
       "\n",
       "         lag8     lag10     lag12  \n",
       "13   0.286266 -0.167258 -1.542319  \n",
       "14   0.148883  0.043595 -0.647762  \n",
       "15   0.192950  0.286266 -0.167258  \n",
       "16   0.460418  0.148883  0.043595  \n",
       "17   3.525207  0.192950  0.286266  \n",
       "..        ...       ...       ...  \n",
       "543  0.187678  0.030006 -0.484596  \n",
       "544  0.506068  0.054814 -0.175886  \n",
       "545  1.071958  0.187678  0.030006  \n",
       "546 -0.250176  0.506068  0.054814  \n",
       "547 -0.048891  1.071958  0.187678  \n",
       "\n",
       "[535 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use loop to tell it how many `lags` we need, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 lags=[1 * (i+1) for i in range(12)],\n",
    "                 target_transforms=[Differences([1]),StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag9</th>\n",
       "      <th>lag10</th>\n",
       "      <th>lag11</th>\n",
       "      <th>lag12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1973-02-01</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>-0.647762</td>\n",
       "      <td>-1.542319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1973-03-01</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>-0.647762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1973-04-01</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.167258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1973-05-01</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1973-06-01</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.175886</td>\n",
       "      <td>-0.484596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.175886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1.265114</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y unique_id      lag1      lag2      lag3      lag4  \\\n",
       "13  1973-02-01 -1.559507         1 -1.630153  0.035355 -0.153337  3.525207   \n",
       "14  1973-03-01 -0.853964         1 -1.559507 -1.630153  0.035355 -0.153337   \n",
       "15  1973-04-01  0.070407         1 -0.853964 -1.559507 -1.630153  0.035355   \n",
       "16  1973-05-01  0.147488         1  0.070407 -0.853964 -1.559507 -1.630153   \n",
       "17  1973-06-01  0.346580         1  0.147488  0.070407 -0.853964 -1.559507   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "543 2017-04-01  0.238379         1 -0.918485  0.437194 -0.779530 -0.048891   \n",
       "544 2017-05-01 -0.615733         1  0.238379 -0.918485  0.437194 -0.779530   \n",
       "545 2017-06-01  0.246907         1 -0.615733  0.238379 -0.918485  0.437194   \n",
       "546 2017-07-01 -0.184723         1  0.246907 -0.615733  0.238379 -0.918485   \n",
       "547 2017-08-01  1.265114         1 -0.184723  0.246907 -0.615733  0.238379   \n",
       "\n",
       "         lag5      lag6      lag7      lag8      lag9     lag10     lag11  \\\n",
       "13   0.460418  0.192950  0.148883  0.286266  0.043595 -0.167258 -0.647762   \n",
       "14   3.525207  0.460418  0.192950  0.148883  0.286266  0.043595 -0.167258   \n",
       "15  -0.153337  3.525207  0.460418  0.192950  0.148883  0.286266  0.043595   \n",
       "16   0.035355 -0.153337  3.525207  0.460418  0.192950  0.148883  0.286266   \n",
       "17  -1.630153  0.035355 -0.153337  3.525207  0.460418  0.192950  0.148883   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "543 -0.250176  1.071958  0.506068  0.187678  0.054814  0.030006 -0.175886   \n",
       "544 -0.048891 -0.250176  1.071958  0.506068  0.187678  0.054814  0.030006   \n",
       "545 -0.779530 -0.048891 -0.250176  1.071958  0.506068  0.187678  0.054814   \n",
       "546  0.437194 -0.779530 -0.048891 -0.250176  1.071958  0.506068  0.187678   \n",
       "547 -0.918485  0.437194 -0.779530 -0.048891 -0.250176  1.071958  0.506068   \n",
       "\n",
       "        lag12  \n",
       "13  -1.542319  \n",
       "14  -0.647762  \n",
       "15  -0.167258  \n",
       "16   0.043595  \n",
       "17   0.286266  \n",
       "..        ...  \n",
       "543 -0.484596  \n",
       "544 -0.175886  \n",
       "545  0.030006  \n",
       "546  0.054814  \n",
       "547  0.187678  \n",
       "\n",
       "[535 rows x 15 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.4 Lag transforms**\n",
    "\n",
    "Let's now look at the `lag_transforms` parameter, as we mentioned before, there are a number of `lag_transforms` that we can use, depending on the need that is required with the data we are using, as well as you can build your own, let's look at a couple of examples of use.\n",
    "\n",
    "First we must call the function we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`expanding.mean` is a `window_ops` function that calculates the expanded moving average of a time series. The expanded moving average is a measure of central tendency that is calculated by adding the time series values as new data is added.\n",
    "\n",
    "The `expanding.mean` can be used to identify trends in time series. For example, if the `expanding.mean` is increasing, it means the time series is in an uptrend. If the expanded moving average is decreasing, it means that the time series is in a downtrend.\n",
    "\n",
    "The `expanding.mean` can also be used to smooth out random fluctuations in a time series. This can be useful for identifying patterns in the time series that would otherwise be difficult to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 lags=[1 * (i+1) for i in range(12)],\n",
    "                 lag_transforms={1: [expanding_mean] },\n",
    "                 target_transforms=[Differences([1]),StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag9</th>\n",
       "      <th>lag10</th>\n",
       "      <th>lag11</th>\n",
       "      <th>lag12</th>\n",
       "      <th>expanding_mean_lag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1973-02-01</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>-0.647762</td>\n",
       "      <td>-1.542319</td>\n",
       "      <td>0.045987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1973-03-01</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>-0.647762</td>\n",
       "      <td>-0.077512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1973-04-01</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.167258</td>\n",
       "      <td>-0.132973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1973-05-01</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>-0.119414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1973-06-01</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>0.148883</td>\n",
       "      <td>0.286266</td>\n",
       "      <td>-0.102733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.175886</td>\n",
       "      <td>-0.484596</td>\n",
       "      <td>-0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.175886</td>\n",
       "      <td>-0.001310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>-0.001982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1.265114</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>-0.002317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y unique_id      lag1      lag2      lag3      lag4  \\\n",
       "13  1973-02-01 -1.559507         1 -1.630153  0.035355 -0.153337  3.525207   \n",
       "14  1973-03-01 -0.853964         1 -1.559507 -1.630153  0.035355 -0.153337   \n",
       "15  1973-04-01  0.070407         1 -0.853964 -1.559507 -1.630153  0.035355   \n",
       "16  1973-05-01  0.147488         1  0.070407 -0.853964 -1.559507 -1.630153   \n",
       "17  1973-06-01  0.346580         1  0.147488  0.070407 -0.853964 -1.559507   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "543 2017-04-01  0.238379         1 -0.918485  0.437194 -0.779530 -0.048891   \n",
       "544 2017-05-01 -0.615733         1  0.238379 -0.918485  0.437194 -0.779530   \n",
       "545 2017-06-01  0.246907         1 -0.615733  0.238379 -0.918485  0.437194   \n",
       "546 2017-07-01 -0.184723         1  0.246907 -0.615733  0.238379 -0.918485   \n",
       "547 2017-08-01  1.265114         1 -0.184723  0.246907 -0.615733  0.238379   \n",
       "\n",
       "         lag5      lag6      lag7      lag8      lag9     lag10     lag11  \\\n",
       "13   0.460418  0.192950  0.148883  0.286266  0.043595 -0.167258 -0.647762   \n",
       "14   3.525207  0.460418  0.192950  0.148883  0.286266  0.043595 -0.167258   \n",
       "15  -0.153337  3.525207  0.460418  0.192950  0.148883  0.286266  0.043595   \n",
       "16   0.035355 -0.153337  3.525207  0.460418  0.192950  0.148883  0.286266   \n",
       "17  -1.630153  0.035355 -0.153337  3.525207  0.460418  0.192950  0.148883   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "543 -0.250176  1.071958  0.506068  0.187678  0.054814  0.030006 -0.175886   \n",
       "544 -0.048891 -0.250176  1.071958  0.506068  0.187678  0.054814  0.030006   \n",
       "545 -0.779530 -0.048891 -0.250176  1.071958  0.506068  0.187678  0.054814   \n",
       "546  0.437194 -0.779530 -0.048891 -0.250176  1.071958  0.506068  0.187678   \n",
       "547 -0.918485  0.437194 -0.779530 -0.048891 -0.250176  1.071958  0.506068   \n",
       "\n",
       "        lag12  expanding_mean_lag1  \n",
       "13  -1.542319             0.045987  \n",
       "14  -0.647762            -0.077512  \n",
       "15  -0.167258            -0.132973  \n",
       "16   0.043595            -0.119414  \n",
       "17   0.286266            -0.102733  \n",
       "..        ...                  ...  \n",
       "543 -0.484596            -0.001753  \n",
       "544 -0.175886            -0.001310  \n",
       "545  0.030006            -0.002440  \n",
       "546  0.054814            -0.001982  \n",
       "547  0.187678            -0.002317  \n",
       "\n",
       "[535 rows x 16 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example, using the `rolling_mean` function.\n",
    "\n",
    "Rolling_mean is a technique used to smooth time series data. This is done by calculating the average of the time series values over a given time period. The time period used to calculate the average is called the window.\n",
    "\n",
    "The `rolling_mean` can be used to identify trends in a time series. For example, if the moving average is rising, it means that the time series is in an uptrend. If the moving average is decreasing, it means that the time series is in a downtrend.\n",
    "\n",
    "The `rolling_mean` can also be used to smooth out random fluctuations in a time series. This can be useful for identifying patterns in the time series that would otherwise be difficult to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                 freq='MS', \n",
    "                 lags=[1 * (i+1) for i in range(12)],\n",
    "                 lag_transforms={1: [expanding_mean], 12: [(rolling_mean, 7)] },\n",
    "                 target_transforms=[Differences([1]),StandardScaler()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag9</th>\n",
       "      <th>lag10</th>\n",
       "      <th>lag11</th>\n",
       "      <th>lag12</th>\n",
       "      <th>expanding_mean_lag1</th>\n",
       "      <th>rolling_mean_lag12_window_size7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1973-08-01</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.317732</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>0.192950</td>\n",
       "      <td>-0.089716</td>\n",
       "      <td>-0.240806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1973-09-01</td>\n",
       "      <td>0.815643</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>-0.317732</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>0.460418</td>\n",
       "      <td>-0.078719</td>\n",
       "      <td>0.045299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1973-10-01</td>\n",
       "      <td>2.467097</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815643</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>-0.317732</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>3.525207</td>\n",
       "      <td>-0.034001</td>\n",
       "      <td>0.641437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1973-11-01</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>1</td>\n",
       "      <td>2.467097</td>\n",
       "      <td>0.815643</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>-0.317732</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>-0.153337</td>\n",
       "      <td>0.085099</td>\n",
       "      <td>0.643426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1973-12-01</td>\n",
       "      <td>-0.452213</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695558</td>\n",
       "      <td>2.467097</td>\n",
       "      <td>0.815643</td>\n",
       "      <td>0.119225</td>\n",
       "      <td>-0.317732</td>\n",
       "      <td>0.346580</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.853964</td>\n",
       "      <td>-1.559507</td>\n",
       "      <td>-1.630153</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>0.112847</td>\n",
       "      <td>0.642249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.175886</td>\n",
       "      <td>-0.484596</td>\n",
       "      <td>-0.001753</td>\n",
       "      <td>-0.200003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.175886</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>-0.395931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>-0.002440</td>\n",
       "      <td>-0.355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.054814</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.279231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1.265114</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.184723</td>\n",
       "      <td>0.246907</td>\n",
       "      <td>-0.615733</td>\n",
       "      <td>0.238379</td>\n",
       "      <td>-0.918485</td>\n",
       "      <td>0.437194</td>\n",
       "      <td>-0.779530</td>\n",
       "      <td>-0.048891</td>\n",
       "      <td>-0.250176</td>\n",
       "      <td>1.071958</td>\n",
       "      <td>0.506068</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>-0.065965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds         y unique_id      lag1      lag2      lag3      lag4  \\\n",
       "19  1973-08-01  0.119225         1 -0.317732  0.346580  0.147488  0.070407   \n",
       "20  1973-09-01  0.815643         1  0.119225 -0.317732  0.346580  0.147488   \n",
       "21  1973-10-01  2.467097         1  0.815643  0.119225 -0.317732  0.346580   \n",
       "22  1973-11-01  0.695558         1  2.467097  0.815643  0.119225 -0.317732   \n",
       "23  1973-12-01 -0.452213         1  0.695558  2.467097  0.815643  0.119225   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "543 2017-04-01  0.238379         1 -0.918485  0.437194 -0.779530 -0.048891   \n",
       "544 2017-05-01 -0.615733         1  0.238379 -0.918485  0.437194 -0.779530   \n",
       "545 2017-06-01  0.246907         1 -0.615733  0.238379 -0.918485  0.437194   \n",
       "546 2017-07-01 -0.184723         1  0.246907 -0.615733  0.238379 -0.918485   \n",
       "547 2017-08-01  1.265114         1 -0.184723  0.246907 -0.615733  0.238379   \n",
       "\n",
       "         lag5      lag6      lag7      lag8      lag9     lag10     lag11  \\\n",
       "19  -0.853964 -1.559507 -1.630153  0.035355 -0.153337  3.525207  0.460418   \n",
       "20   0.070407 -0.853964 -1.559507 -1.630153  0.035355 -0.153337  3.525207   \n",
       "21   0.147488  0.070407 -0.853964 -1.559507 -1.630153  0.035355 -0.153337   \n",
       "22   0.346580  0.147488  0.070407 -0.853964 -1.559507 -1.630153  0.035355   \n",
       "23  -0.317732  0.346580  0.147488  0.070407 -0.853964 -1.559507 -1.630153   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "543 -0.250176  1.071958  0.506068  0.187678  0.054814  0.030006 -0.175886   \n",
       "544 -0.048891 -0.250176  1.071958  0.506068  0.187678  0.054814  0.030006   \n",
       "545 -0.779530 -0.048891 -0.250176  1.071958  0.506068  0.187678  0.054814   \n",
       "546  0.437194 -0.779530 -0.048891 -0.250176  1.071958  0.506068  0.187678   \n",
       "547 -0.918485  0.437194 -0.779530 -0.048891 -0.250176  1.071958  0.506068   \n",
       "\n",
       "        lag12  expanding_mean_lag1  rolling_mean_lag12_window_size7  \n",
       "19   0.192950            -0.089716                        -0.240806  \n",
       "20   0.460418            -0.078719                         0.045299  \n",
       "21   3.525207            -0.034001                         0.641437  \n",
       "22  -0.153337             0.085099                         0.643426  \n",
       "23   0.035355             0.112847                         0.642249  \n",
       "..        ...                  ...                              ...  \n",
       "543 -0.484596            -0.001753                        -0.200003  \n",
       "544 -0.175886            -0.001310                        -0.395931  \n",
       "545  0.030006            -0.002440                        -0.355600  \n",
       "546  0.054814            -0.001982                        -0.279231  \n",
       "547  0.187678            -0.002317                        -0.065965  \n",
       "\n",
       "[529 rows x 17 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we can add as many `lags` as we want or need, as well as we can add the different `lag_transforms` functions that we are going to use or need depending on the case of our data set. In this tutorial our main objective is to teach you how to use the different types of tools and not to perform a particular data analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have already added the number of `lags` and `lag_transforms` to our model, then the next step would be to train our model and make the predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.5 Fit method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLForecast(models=[RandomForestRegressor], freq=<MonthBegin>, lag_features=['lag1', 'lag2', 'lag3', 'lag4', 'lag5', 'lag6', 'lag7', 'lag8', 'lag9', 'lag10', 'lag11', 'lag12', 'expanding_mean_lag1', 'rolling_mean_lag12_window_size7'], date_features=[], num_threads=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the models\n",
    "mlf.fit(df,  \n",
    " fitted=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the results of our model in this case the `RandomForestRegressor model`. We can observe it with the following instruction:\n",
    "\n",
    "Let us now visualize the fitted values of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-08-01</td>\n",
       "      <td>73.1748</td>\n",
       "      <td>0.272443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-09-01</td>\n",
       "      <td>80.5915</td>\n",
       "      <td>0.395592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-10-01</td>\n",
       "      <td>102.9200</td>\n",
       "      <td>2.377738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-11-01</td>\n",
       "      <td>109.2524</td>\n",
       "      <td>-0.190402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-12-01</td>\n",
       "      <td>105.2210</td>\n",
       "      <td>-0.174462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>107.4288</td>\n",
       "      <td>-0.271510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>101.9209</td>\n",
       "      <td>-0.219328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>104.2022</td>\n",
       "      <td>-0.175975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>102.5861</td>\n",
       "      <td>-0.164648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>114.0613</td>\n",
       "      <td>0.272443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds         y  RandomForestRegressor\n",
       "unique_id                                            \n",
       "1         1973-08-01   73.1748               0.272443\n",
       "1         1973-09-01   80.5915               0.395592\n",
       "1         1973-10-01  102.9200               2.377738\n",
       "1         1973-11-01  109.2524              -0.190402\n",
       "1         1973-12-01  105.2210              -0.174462\n",
       "...              ...       ...                    ...\n",
       "1         2017-04-01  107.4288              -0.271510\n",
       "1         2017-05-01  101.9209              -0.219328\n",
       "1         2017-06-01  104.2022              -0.175975\n",
       "1         2017-07-01  102.5861              -0.164648\n",
       "1         2017-08-01  114.0613               0.272443\n",
       "\n",
       "[529 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=mlf.forecast_fitted_values()\n",
    "result=result.set_index(\"unique_id\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import normal_ad\n",
    "from scipy import stats\n",
    "\n",
    "sw_result = stats.shapiro(result[\"RandomForestRegressor\"])\n",
    "ad_result = normal_ad(np.array(result[\"RandomForestRegressor\"]), axis=0)\n",
    "dag_result = stats.normaltest(result[\"RandomForestRegressor\"], axis=0, nan_policy='propagate')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that we can only use this method if we assume that the residuals of our validation predictions are normally distributed. To see if this is the case, we will use a PP-plot and test its normality with the Anderson-Darling, Kolmogorov-Smirnov, and D’Agostino K^2 tests.\n",
    "\n",
    "The PP-plot(Probability-to-Probability) plots the data sample against the normal distribution plot in such a way that if normally distributed, the data points will form a straight line.\n",
    "\n",
    "The three normality tests determine how likely a data sample is from a normally distributed population using p-values. The null hypothesis for each test is that \"the sample came from a normally distributed population\". This means that if the resulting p-values are below a chosen alpha value, then the null hypothesis is rejected. Thus there is evidence to suggest that the data comes from a non-normal distribution. For this article, we will use an Alpha value of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=mlf.forecast_fitted_values()\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "# plot[1,1]\n",
    "result[\"RandomForestRegressor\"].plot(ax=axs[0,0])\n",
    "axs[0,0].set_title(\"Residuals model\");\n",
    "\n",
    "# plot\n",
    "#plot(result[\"XGBRegressor\"], ax=axs[0,1]);\n",
    "axs[0,1].hist(result[\"RandomForestRegressor\"], density=True,bins=50, alpha=0.5 )\n",
    "axs[0,1].set_title(\"Density plot - Residual\");\n",
    "\n",
    "# plot\n",
    "stats.probplot(result[\"RandomForestRegressor\"], dist=\"norm\", plot=axs[1,0])\n",
    "axs[1,0].set_title('Plot Q-Q')\n",
    "axs[1,0].annotate(\"SW p-val: {:.4f}\".format(sw_result[1]), xy=(0.05,0.9), xycoords='axes fraction', fontsize=15,\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
    "\n",
    "axs[1,0].annotate(\"AD p-val: {:.4f}\".format(ad_result[1]), xy=(0.05,0.8), xycoords='axes fraction', fontsize=15,\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
    "\n",
    "axs[1,0].annotate(\"DAG p-val: {:.4f}\".format(dag_result[1]), xy=(0.05,0.7), xycoords='axes fraction', fontsize=15,\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
    "# plot\n",
    "plot_acf(result[\"RandomForestRegressor\"],  lags=35, ax=axs[1,1],color=\"fuchsia\")\n",
    "axs[1,1].set_title(\"Autocorrelation\");\n",
    "\n",
    "plt.savefig(\"../figs/lag_transforms__plot_residual_model.png\")\n",
    "plt.close();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__plot_residual_model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.6 Predict method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>RandomForestRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>117.745812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>122.941271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>113.789280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>112.151540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>108.392895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>111.863494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>108.070508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>110.778103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>107.073480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>110.292415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>108.363855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>118.339988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>121.760969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>125.445482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>121.161084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>119.232524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>116.894713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>120.315695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>117.977884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>121.367075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>119.044310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>122.448491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>120.436858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>125.745973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>129.158612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>132.579593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>130.179854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>128.168221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>126.134597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>129.547236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds  RandomForestRegressor\n",
       "0          1 2017-09-01             117.745812\n",
       "1          1 2017-10-01             122.941271\n",
       "2          1 2017-11-01             113.789280\n",
       "3          1 2017-12-01             112.151540\n",
       "4          1 2018-01-01             108.392895\n",
       "5          1 2018-02-01             111.863494\n",
       "6          1 2018-03-01             108.070508\n",
       "7          1 2018-04-01             110.778103\n",
       "8          1 2018-05-01             107.073480\n",
       "9          1 2018-06-01             110.292415\n",
       "10         1 2018-07-01             108.363855\n",
       "11         1 2018-08-01             118.339988\n",
       "12         1 2018-09-01             121.760969\n",
       "13         1 2018-10-01             125.445482\n",
       "14         1 2018-11-01             121.161084\n",
       "15         1 2018-12-01             119.232524\n",
       "16         1 2019-01-01             116.894713\n",
       "17         1 2019-02-01             120.315695\n",
       "18         1 2019-03-01             117.977884\n",
       "19         1 2019-04-01             121.367075\n",
       "20         1 2019-05-01             119.044310\n",
       "21         1 2019-06-01             122.448491\n",
       "22         1 2019-07-01             120.436858\n",
       "23         1 2019-08-01             125.745973\n",
       "24         1 2019-09-01             129.158612\n",
       "25         1 2019-10-01             132.579593\n",
       "26         1 2019-11-01             130.179854\n",
       "27         1 2019-12-01             128.168221\n",
       "28         1 2020-01-01             126.134597\n",
       "29         1 2020-02-01             129.547236"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df = mlf.predict(h=30) \n",
    "\n",
    "forecast_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.7 Plot prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plot_series(df, forecast_df, max_insample_length=300,engine=\"matplotlib\")\n",
    "for ax in fig.get_axes():\n",
    "   ax.set_title(\"Prediction\")\n",
    "fig.savefig('../figs/lag_transforms__plot_forecasting_intervals.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__plot_forecasting_intervals.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the feature importances too.\n",
    "\n",
    "This model is heavily dependent on the lag 12 feature, as you can see in the feature importance plot for `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=pd.Series(mlf.models_['RandomForestRegressor'].feature_importances_, \n",
    "              index=mlf.ts.features_order_).sort_values(ascending=False).plot.bar(title='Feature Importance RandomForestRegressor')\n",
    "plt.savefig('../figs/lag_transforms__plot_feature_importance.png',dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/lag_transforms__plot_feature_importance.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that adding `lags` to our time series model is important for several reasons:\n",
    "\n",
    "1. Capture of temporal dependencies: Lags allow capturing temporal dependence in time series data. By including lags as predictor variables in the model, the influence of past values in predicting future values is being considered. This is essential, since in time series it is common for present values to be correlated with past values.\n",
    "\n",
    "2. Modeling trends and seasonality: Lags are especially useful for modeling trends and seasonal patterns in time series. By considering lags corresponding to the relevant time periods (for example, monthly lags or quarterly lags), seasonality and regular fluctuations in the data can be captured. This is essential to correctly understand and predict repetitive patterns in the series.\n",
    "\n",
    "3. Improved predictive capacity: By incorporating lags into the model, the model's ability to predict future values of the time series is increased. This is because lags provide valuable information about the series' past dynamics and behavior, which can help make more accurate and realistic projections.\n",
    "\n",
    "4. Identification of autocorrelation structures: By analyzing the lag coefficients in the model, autocorrelation structures can be identified in the time series. For example, if the lag coefficients are significantly different from zero, it indicates the presence of a dependency relationship between past and present values. This can be useful in understanding the nature and properties of the series.\n",
    "\n",
    "In summary, adding lags to a time series model is important because it allows you to capture time dependence, model trends and seasonality, improve predictive ability, and detect autocorrelation structures in the data. Lags provide valuable information and allow the construction of more sophisticated and accurate models for time series analysis and forecasting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. References** <a class=\"anchor\" id=\"10\"></a>\n",
    "\n",
    "[Table of Contents](#0)\n",
    "\n",
    "1. Changquan Huang • Alla Petukhina. Springer series (2022). Applied Time Series Analysis and Forecasting with Python. \n",
    "2. Ivan Svetunkov. [Forecasting and Analytics with the Augmented Dynamic Adaptive Model (ADAM)](https://openforecast.org/adam/)\n",
    "3. [James D. Hamilton. Time Series Analysis Princeton University Press, Princeton, New Jersey, 1st Edition, 1994.](https://press.princeton.edu/books/hardcover/9780691042893/time-series-analysis)\n",
    "4. [Nixtla Parameters for Mlforecast](https://nixtla.github.io/mlforecast/forecast.html).\n",
    "5. [Pandas available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).\n",
    "6. [Rob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, Time series cross-validation”.](https://otexts.com/fpp3/tscv.html).\n",
    "7. [Seasonal periods- Rob J Hyndman](https://robjhyndman.com/hyndsight/seasonal-periods/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
