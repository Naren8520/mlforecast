{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main objective of the following article is to get a step-by-step guide on how to include exogenous variables and predict interval to our Time Series model using `Mlforecast`.\n",
    "\n",
    "During this walkthrough, we will become familiar with the main `MlForecast` class and some relevant methods such as `mlforecast.fit`, `mlforecast.predict` and `mlforecast.cross_validation` in other.\n",
    "\n",
    "Let's start!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "\n",
    "\n",
    "\n",
    "1.\t[Introduction](#1)\n",
    "2.\t[Loading libraries and data](#3)\n",
    "3.\t[Explore Data with the plot method](#3)\n",
    "4.\t[Training A Multivariate Time Series Model With MLForecast](#4)\n",
    "5.  [Feature importances](#5)\n",
    "6.  [Evaluate the model’s performance](#6)\n",
    "7.  [Evaluate the model](#7)\n",
    "8.  [References](#8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction** <a class=\"anchor\" id=\"\"></a>\n",
    "\n",
    "[Table of Contents](#0)\n",
    "\n",
    "Multivariate time series models are statistical or machine learning models used to analyze data sets consisting of multiple time series variables that are believed to be interrelated and influence each other over time. These models capture the complex relationships and dynamics between different variables and enable more accurate forecasting and analysis compared to univariate time series models. The models use machine learning algorithms to capture the complex relationships and dynamics between multiple time series variables.\n",
    "\n",
    "Unlike traditional statistical models such as VAR, which are based on specific assumptions, multivariate time series models with machine learning have the advantage of being more flexible and capable of capturing non-linear patterns and complex dependencies between variables.\n",
    "\n",
    "In a multivariate time series model, each dependent variable is modeled as a linear or nonlinear function of its past values and the past values of the other variables in the system. The central idea is that the variables in the system are considered endogenous, that is, they are influenced by other variables within the system rather than being independent of each other.\n",
    "\n",
    "Multivariate time series models with machine learning offer the ability to model and forecast complex time series with multiple variables, allowing for greater flexibility and the ability to capture non-linear relationships. However, they may also require more data and greater preprocessing effort compared to traditional statistical models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading libraries and data** <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling and processing of Data\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Handling and processing of Data for Date (time)\n",
    "# ==============================================================================\n",
    "import datetime\n",
    "import datetime as dt\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# \n",
    "# ==============================================================================\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose \n",
    "# \n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "# ==============================================================================\n",
    "import xgboost as xgb\n",
    "\n",
    "# Mlforecast\n",
    "# ==============================================================================\n",
    "from mlforecast import MLForecast\n",
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "from window_ops.ewm import ewm_mean\n",
    "from mlforecast.target_transforms import Differences\n",
    "\n",
    "from mlforecast.utils import PredictionIntervals\n",
    "from mlforecast.utils import generate_daily_series, generate_prices_for_series\n",
    "from utilsforecast.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.style.use('grayscale') # fivethirtyeight  grayscale  classic\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "dark_style = {\n",
    "    'figure.facecolor': '#212946',  #   #008080\n",
    "    'axes.facecolor': '#212946',\n",
    "    'savefig.facecolor': '#212946',\n",
    "    'axes.grid': True,\n",
    "    'axes.grid.which': 'both',\n",
    "    'axes.spines.left': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.bottom': False,\n",
    "    'grid.color': '#000000',  #2A3459\n",
    "    'grid.linewidth': '1',\n",
    "    'text.color': '0.9',\n",
    "    'axes.labelcolor': '0.9',\n",
    "    'xtick.color': '0.9',\n",
    "    'ytick.color': '0.9',\n",
    "    'font.size': 12 }\n",
    "plt.rcParams.update(dark_style)\n",
    "# Define the plot size\n",
    "# ==============================================================================\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18,7)\n",
    "\n",
    "# Hide warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>generation biomass</th>\n",
       "      <th>generation fossil brown coal/lignite</th>\n",
       "      <th>generation fossil gas</th>\n",
       "      <th>generation fossil hard coal</th>\n",
       "      <th>generation fossil oil</th>\n",
       "      <th>generation hydro pumped storage consumption</th>\n",
       "      <th>generation hydro run-of-river and poundage</th>\n",
       "      <th>generation hydro water reservoir</th>\n",
       "      <th>generation nuclear</th>\n",
       "      <th>generation other</th>\n",
       "      <th>generation other renewable</th>\n",
       "      <th>generation solar</th>\n",
       "      <th>generation waste</th>\n",
       "      <th>generation wind onshore</th>\n",
       "      <th>total load actual</th>\n",
       "      <th>price day ahead</th>\n",
       "      <th>price actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>447.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>4821.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>7096.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>6378.0</td>\n",
       "      <td>25385.0</td>\n",
       "      <td>50.10</td>\n",
       "      <td>65.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>449.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>5196.0</td>\n",
       "      <td>4755.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>7096.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>24382.0</td>\n",
       "      <td>48.10</td>\n",
       "      <td>64.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>448.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>4857.0</td>\n",
       "      <td>4581.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>5461.0</td>\n",
       "      <td>22734.0</td>\n",
       "      <td>47.33</td>\n",
       "      <td>64.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>438.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>4314.0</td>\n",
       "      <td>4131.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>7098.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>21286.0</td>\n",
       "      <td>42.27</td>\n",
       "      <td>59.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>428.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>7097.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>20264.0</td>\n",
       "      <td>38.41</td>\n",
       "      <td>56.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  generation biomass  \\\n",
       "0 2015-01-01 00:00:00               447.0   \n",
       "1 2015-01-01 01:00:00               449.0   \n",
       "2 2015-01-01 02:00:00               448.0   \n",
       "3 2015-01-01 03:00:00               438.0   \n",
       "4 2015-01-01 04:00:00               428.0   \n",
       "\n",
       "   generation fossil brown coal/lignite  generation fossil gas  \\\n",
       "0                                 329.0                 4844.0   \n",
       "1                                 328.0                 5196.0   \n",
       "2                                 323.0                 4857.0   \n",
       "3                                 254.0                 4314.0   \n",
       "4                                 187.0                 4130.0   \n",
       "\n",
       "   generation fossil hard coal  generation fossil oil  \\\n",
       "0                       4821.0                  162.0   \n",
       "1                       4755.0                  158.0   \n",
       "2                       4581.0                  157.0   \n",
       "3                       4131.0                  160.0   \n",
       "4                       3840.0                  156.0   \n",
       "\n",
       "   generation hydro pumped storage consumption  \\\n",
       "0                                        863.0   \n",
       "1                                        920.0   \n",
       "2                                       1164.0   \n",
       "3                                       1503.0   \n",
       "4                                       1826.0   \n",
       "\n",
       "   generation hydro run-of-river and poundage  \\\n",
       "0                                      1051.0   \n",
       "1                                      1009.0   \n",
       "2                                       973.0   \n",
       "3                                       949.0   \n",
       "4                                       953.0   \n",
       "\n",
       "   generation hydro water reservoir  generation nuclear  generation other  \\\n",
       "0                            1899.0              7096.0              43.0   \n",
       "1                            1658.0              7096.0              43.0   \n",
       "2                            1371.0              7099.0              43.0   \n",
       "3                             779.0              7098.0              43.0   \n",
       "4                             720.0              7097.0              43.0   \n",
       "\n",
       "   generation other renewable  generation solar  generation waste  \\\n",
       "0                        73.0              49.0             196.0   \n",
       "1                        71.0              50.0             195.0   \n",
       "2                        73.0              50.0             196.0   \n",
       "3                        75.0              50.0             191.0   \n",
       "4                        74.0              42.0             189.0   \n",
       "\n",
       "   generation wind onshore  total load actual  price day ahead  price actual  \n",
       "0                   6378.0            25385.0            50.10         65.41  \n",
       "1                   5890.0            24382.0            48.10         64.92  \n",
       "2                   5461.0            22734.0            47.33         64.48  \n",
       "3                   5238.0            21286.0            42.27         59.32  \n",
       "4                   4935.0            20264.0            38.41         56.04  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/Naren8520/Serie-de-tiempo-con-Machine-Learning/main/Data/energy_dataset.csv\", parse_dates=[\"time\"], usecols=lambda column: column != 'Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35064 entries, 0 to 35063\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                       Non-Null Count  Dtype         \n",
      "---  ------                                       --------------  -----         \n",
      " 0   time                                         35064 non-null  datetime64[ns]\n",
      " 1   generation biomass                           35064 non-null  float64       \n",
      " 2   generation fossil brown coal/lignite         35064 non-null  float64       \n",
      " 3   generation fossil gas                        35064 non-null  float64       \n",
      " 4   generation fossil hard coal                  35064 non-null  float64       \n",
      " 5   generation fossil oil                        35064 non-null  float64       \n",
      " 6   generation hydro pumped storage consumption  35064 non-null  float64       \n",
      " 7   generation hydro run-of-river and poundage   35064 non-null  float64       \n",
      " 8   generation hydro water reservoir             35064 non-null  float64       \n",
      " 9   generation nuclear                           35064 non-null  float64       \n",
      " 10  generation other                             35064 non-null  float64       \n",
      " 11  generation other renewable                   35064 non-null  float64       \n",
      " 12  generation solar                             35064 non-null  float64       \n",
      " 13  generation waste                             35064 non-null  float64       \n",
      " 14  generation wind onshore                      35064 non-null  float64       \n",
      " 15  total load actual                            35064 non-null  float64       \n",
      " 16  price day ahead                              35064 non-null  float64       \n",
      " 17  price actual                                 35064 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(17)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to MlForecast is always a data frame in long format with three columns: unique_id, ds and y:\n",
    "\n",
    "* The `unique_id` (string, int or category) represents an identifier for the series.\n",
    "\n",
    "* The `ds` (datestamp) column should be of a format expected by Pandas, ideally YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\n",
    "\n",
    "* The `y` (numeric) represents the measurement we wish to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>generation biomass</th>\n",
       "      <th>generation fossil brown coal/lignite</th>\n",
       "      <th>generation fossil gas</th>\n",
       "      <th>generation fossil hard coal</th>\n",
       "      <th>generation fossil oil</th>\n",
       "      <th>generation hydro pumped storage consumption</th>\n",
       "      <th>generation hydro run-of-river and poundage</th>\n",
       "      <th>generation hydro water reservoir</th>\n",
       "      <th>generation nuclear</th>\n",
       "      <th>generation other</th>\n",
       "      <th>generation other renewable</th>\n",
       "      <th>generation solar</th>\n",
       "      <th>generation waste</th>\n",
       "      <th>generation wind onshore</th>\n",
       "      <th>total load actual</th>\n",
       "      <th>price day ahead</th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>447.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>4821.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>863.0</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>7096.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>6378.0</td>\n",
       "      <td>25385.0</td>\n",
       "      <td>50.10</td>\n",
       "      <td>65.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>449.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>5196.0</td>\n",
       "      <td>4755.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>7096.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5890.0</td>\n",
       "      <td>24382.0</td>\n",
       "      <td>48.10</td>\n",
       "      <td>64.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>448.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>4857.0</td>\n",
       "      <td>4581.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>5461.0</td>\n",
       "      <td>22734.0</td>\n",
       "      <td>47.33</td>\n",
       "      <td>64.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>438.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>4314.0</td>\n",
       "      <td>4131.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>7098.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>21286.0</td>\n",
       "      <td>42.27</td>\n",
       "      <td>59.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>428.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>7097.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>20264.0</td>\n",
       "      <td>38.41</td>\n",
       "      <td>56.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds  generation biomass  \\\n",
       "0 2015-01-01 00:00:00               447.0   \n",
       "1 2015-01-01 01:00:00               449.0   \n",
       "2 2015-01-01 02:00:00               448.0   \n",
       "3 2015-01-01 03:00:00               438.0   \n",
       "4 2015-01-01 04:00:00               428.0   \n",
       "\n",
       "   generation fossil brown coal/lignite  generation fossil gas  \\\n",
       "0                                 329.0                 4844.0   \n",
       "1                                 328.0                 5196.0   \n",
       "2                                 323.0                 4857.0   \n",
       "3                                 254.0                 4314.0   \n",
       "4                                 187.0                 4130.0   \n",
       "\n",
       "   generation fossil hard coal  generation fossil oil  \\\n",
       "0                       4821.0                  162.0   \n",
       "1                       4755.0                  158.0   \n",
       "2                       4581.0                  157.0   \n",
       "3                       4131.0                  160.0   \n",
       "4                       3840.0                  156.0   \n",
       "\n",
       "   generation hydro pumped storage consumption  \\\n",
       "0                                        863.0   \n",
       "1                                        920.0   \n",
       "2                                       1164.0   \n",
       "3                                       1503.0   \n",
       "4                                       1826.0   \n",
       "\n",
       "   generation hydro run-of-river and poundage  \\\n",
       "0                                      1051.0   \n",
       "1                                      1009.0   \n",
       "2                                       973.0   \n",
       "3                                       949.0   \n",
       "4                                       953.0   \n",
       "\n",
       "   generation hydro water reservoir  generation nuclear  generation other  \\\n",
       "0                            1899.0              7096.0              43.0   \n",
       "1                            1658.0              7096.0              43.0   \n",
       "2                            1371.0              7099.0              43.0   \n",
       "3                             779.0              7098.0              43.0   \n",
       "4                             720.0              7097.0              43.0   \n",
       "\n",
       "   generation other renewable  generation solar  generation waste  \\\n",
       "0                        73.0              49.0             196.0   \n",
       "1                        71.0              50.0             195.0   \n",
       "2                        73.0              50.0             196.0   \n",
       "3                        75.0              50.0             191.0   \n",
       "4                        74.0              42.0             189.0   \n",
       "\n",
       "   generation wind onshore  total load actual  price day ahead      y  \\\n",
       "0                   6378.0            25385.0            50.10  65.41   \n",
       "1                   5890.0            24382.0            48.10  64.92   \n",
       "2                   5461.0            22734.0            47.33  64.48   \n",
       "3                   5238.0            21286.0            42.27  59.32   \n",
       "4                   4935.0            20264.0            38.41  56.04   \n",
       "\n",
       "  unique_id  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"unique_id\"]=\"1\"\n",
    "df=df.rename(columns={\"time\": \"ds\", \"price actual\": \"y\"})\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Explore Data with the plot method** <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "[Table of Contents](#0)\n",
    "\n",
    "We are going to use the `plot_series` function to visualize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_series(df,max_insample_length=1000, palette=\"magma\")\n",
    "fig.savefig('../figs/multivariate_forecasting_and_prediction_intervals__eda.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/multivariate_forecasting_and_prediction_intervals__eda.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Augmented Dickey-Fuller Test**\n",
    "An Augmented Dickey-Fuller (ADF) test is a type of statistical test that determines whether a unit root is present in time series data. Unit roots can cause unpredictable results in time series analysis. A null hypothesis is formed in the unit root test to determine how strongly time series data is affected by a trend. By accepting the null hypothesis, we accept the evidence that the time series data is not stationary. By rejecting the null hypothesis or accepting the alternative hypothesis, we accept the evidence that the time series data is generated by a stationary process. This process is also known as stationary trend. The values of the ADF test statistic are negative. Lower ADF values indicate a stronger rejection of the null hypothesis.\n",
    "\n",
    "Augmented Dickey-Fuller Test is a common statistical test used to test whether a given time series is stationary or not. We can achieve this by defining the null and alternate hypothesis.\n",
    "\n",
    "- Null Hypothesis: Time Series is non-stationary. It gives a time-dependent trend.\n",
    "- Alternate Hypothesis: Time Series is stationary. In another term, the series doesn’t depend on time.\n",
    "\n",
    "- ADF or t Statistic < critical values: Reject the null hypothesis, time series is stationary.\n",
    "- ADF or t Statistic > critical values: Failed to reject the null hypothesis, time series is non-stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_dickey_fuller_test(series , column_name):\n",
    "    print (f'Dickey-Fuller test results for columns: {column_name}')\n",
    "    dftest = adfuller(series, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','No Lags Used','Number of observations used'])\n",
    "    for key,value in dftest[4].items():\n",
    "       dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "    if dftest[1] <= 0.05:\n",
    "        print(\"Conclusion:====>\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"The data is stationary\")\n",
    "    else:\n",
    "        print(\"Conclusion:====>\")\n",
    "        print(\"The null hypothesis cannot be rejected\")\n",
    "        print(\"The data is not stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dickey-Fuller test results for columns: Energy production\n",
      "Test Statistic                -9.147016e+00\n",
      "p-value                        2.750493e-15\n",
      "No Lags Used                   5.000000e+01\n",
      "Number of observations used    3.501300e+04\n",
      "Critical Value (1%)           -3.430537e+00\n",
      "Critical Value (5%)           -2.861623e+00\n",
      "Critical Value (10%)          -2.566814e+00\n",
      "dtype: float64\n",
      "Conclusion:====>\n",
      "Reject the null hypothesis\n",
      "The data is stationary\n"
     ]
    }
   ],
   "source": [
    "augmented_dickey_fuller_test(df[\"y\"],\"Energy production\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training A Multivariate Time Series Model With MLForecast**<a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building Model**\n",
    "\n",
    "Let’s see how we can engineer features and train an `XGBoost` with mlforecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [xgb.XGBRegressor(random_state=0, n_estimators=100)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the models by instantiating a new `MlForecast` object with the following parameters:\n",
    "\n",
    "* `models:` a list of models. Select the models you want from models and import them.\n",
    "\n",
    "* `freq:` a string indicating the frequency of the data. (See [panda’s available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).)\n",
    "\n",
    "* `lags:` Lags of the target to uses as feature.\n",
    "\n",
    "* `lag_transforms:` Mapping of target lags to their transformations.\n",
    "\n",
    "* `date_features:` Features computed from the dates. Can be `pandas` date attributes or functions that will take the dates as input.\n",
    "\n",
    "* `differences:` Differences to take of the target before computing the features. These are restored at the forecasting step.\n",
    "\n",
    "* `num_threads:` Number of threads to use when computing the features.\n",
    "\n",
    "* `target_transforms:` Transformations that will be applied to the target computing the features and restored after the forecasting step.\n",
    "\n",
    "Any settings are passed into the constructor. Then you call its fit method and pass in the historical data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from window_ops.rolling import rolling_mean, rolling_max, rolling_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf = MLForecast(models=model,\n",
    "                   freq='H',\n",
    "                   lags=[1,2,4],\n",
    "                   lag_transforms={\n",
    "                       1: [(rolling_mean, 4), (rolling_min, 4), (rolling_max, 4)], \n",
    "                   },\n",
    "                   date_features=['week', 'month','day'],\n",
    "                   num_threads=6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use any scikit-learn model, or any other model that follows the same API. We could use LightGBM or CatBoost, for example.\n",
    "\n",
    "The MLForecast object will manage the transformation of the data, the training of the models, and the prediction of the target variable.\n",
    "\n",
    "We pass the `freq` parameter to tell `mlforecast` that our data is hourly, and the `lags` parameter to tell it that we want to use the last 1, 2 and 4 hors as features to predict the next hours.\n",
    "\n",
    "We also pass the `lag_transforms` parameter, which is a dictionary that maps the number of lags to a list of functions to apply to the lagged values.\n",
    "\n",
    "The keys are the lags over which we want to apply the functions, and the values are lists of tuples, where the first element is the function to apply, and the second element is the number of weeks to apply it to (the window).\n",
    "\n",
    "So in this case, we will apply the `rolling_mean, rolling_min` and `rolling_max` functions to the last 30 hours of each lag.\n",
    "\n",
    "We are recommend we use the `window_ops` package or create your custom functions with numba.\n",
    "\n",
    "date features is a list of the date components we want to use. These are features like the month, the week of the year, the day of the week (if it was a daily time series), etc.\n",
    "\n",
    "Finally, `num_threads` is the number of threads to use when training the models in parallel. Setting it to the number of cores in your machine is a good idea."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `MLForecast.preprocess` method to explore different transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>generation biomass</th>\n",
       "      <th>generation fossil brown coal/lignite</th>\n",
       "      <th>generation fossil gas</th>\n",
       "      <th>generation fossil hard coal</th>\n",
       "      <th>generation fossil oil</th>\n",
       "      <th>generation hydro pumped storage consumption</th>\n",
       "      <th>generation hydro run-of-river and poundage</th>\n",
       "      <th>generation hydro water reservoir</th>\n",
       "      <th>generation nuclear</th>\n",
       "      <th>...</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag4</th>\n",
       "      <th>rolling_mean_lag1_window_size4</th>\n",
       "      <th>rolling_min_lag1_window_size4</th>\n",
       "      <th>rolling_max_lag1_window_size4</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>428.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4130.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>7097.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>59.32</td>\n",
       "      <td>64.48</td>\n",
       "      <td>65.41</td>\n",
       "      <td>63.5325</td>\n",
       "      <td>59.32</td>\n",
       "      <td>65.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>410.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>7098.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>56.04</td>\n",
       "      <td>59.32</td>\n",
       "      <td>64.92</td>\n",
       "      <td>61.1900</td>\n",
       "      <td>56.04</td>\n",
       "      <td>64.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-01 06:00:00</td>\n",
       "      <td>401.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>3368.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>7098.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>53.63</td>\n",
       "      <td>56.04</td>\n",
       "      <td>64.48</td>\n",
       "      <td>58.3675</td>\n",
       "      <td>53.63</td>\n",
       "      <td>64.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>408.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>4030.0</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2031.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>51.73</td>\n",
       "      <td>53.63</td>\n",
       "      <td>59.32</td>\n",
       "      <td>55.1800</td>\n",
       "      <td>51.73</td>\n",
       "      <td>59.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-01 08:00:00</td>\n",
       "      <td>413.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4052.0</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2119.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>7098.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>51.43</td>\n",
       "      <td>51.73</td>\n",
       "      <td>56.04</td>\n",
       "      <td>53.2075</td>\n",
       "      <td>51.43</td>\n",
       "      <td>56.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds  generation biomass  \\\n",
       "4 2015-01-01 04:00:00               428.0   \n",
       "5 2015-01-01 05:00:00               410.0   \n",
       "6 2015-01-01 06:00:00               401.0   \n",
       "7 2015-01-01 07:00:00               408.0   \n",
       "8 2015-01-01 08:00:00               413.0   \n",
       "\n",
       "   generation fossil brown coal/lignite  generation fossil gas  \\\n",
       "4                                 187.0                 4130.0   \n",
       "5                                 178.0                 4038.0   \n",
       "6                                 172.0                 4040.0   \n",
       "7                                 172.0                 4030.0   \n",
       "8                                 177.0                 4052.0   \n",
       "\n",
       "   generation fossil hard coal  generation fossil oil  \\\n",
       "4                       3840.0                  156.0   \n",
       "5                       3590.0                  156.0   \n",
       "6                       3368.0                  158.0   \n",
       "7                       3208.0                  160.0   \n",
       "8                       3335.0                  161.0   \n",
       "\n",
       "   generation hydro pumped storage consumption  \\\n",
       "4                                       1826.0   \n",
       "5                                       2109.0   \n",
       "6                                       2108.0   \n",
       "7                                       2031.0   \n",
       "8                                       2119.0   \n",
       "\n",
       "   generation hydro run-of-river and poundage  \\\n",
       "4                                       953.0   \n",
       "5                                       952.0   \n",
       "6                                       961.0   \n",
       "7                                       983.0   \n",
       "8                                      1001.0   \n",
       "\n",
       "   generation hydro water reservoir  generation nuclear  ...  unique_id  \\\n",
       "4                             720.0              7097.0  ...          1   \n",
       "5                             743.0              7098.0  ...          1   \n",
       "6                             848.0              7098.0  ...          1   \n",
       "7                            1012.0              7099.0  ...          1   \n",
       "8                            1015.0              7098.0  ...          1   \n",
       "\n",
       "    lag1   lag2   lag4  rolling_mean_lag1_window_size4  \\\n",
       "4  59.32  64.48  65.41                         63.5325   \n",
       "5  56.04  59.32  64.92                         61.1900   \n",
       "6  53.63  56.04  64.48                         58.3675   \n",
       "7  51.73  53.63  59.32                         55.1800   \n",
       "8  51.43  51.73  56.04                         53.2075   \n",
       "\n",
       "   rolling_min_lag1_window_size4  rolling_max_lag1_window_size4  week month  \\\n",
       "4                          59.32                          65.41     1     1   \n",
       "5                          56.04                          64.92     1     1   \n",
       "6                          53.63                          64.48     1     1   \n",
       "7                          51.73                          59.32     1     1   \n",
       "8                          51.43                          56.04     1     1   \n",
       "\n",
       "   day  \n",
       "4    1  \n",
       "5    1  \n",
       "6    1  \n",
       "7    1  \n",
       "8    1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = mlf.preprocess(df)\n",
    "prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation biomass                             0.142659\n",
       "generation fossil brown coal/lignite           0.364009\n",
       "generation fossil gas                          0.461447\n",
       "generation fossil hard coal                    0.465645\n",
       "generation fossil oil                          0.285258\n",
       "generation hydro pumped storage consumption   -0.426265\n",
       "generation hydro run-of-river and poundage    -0.136663\n",
       "generation hydro water reservoir               0.071858\n",
       "generation nuclear                            -0.053030\n",
       "generation other                               0.099919\n",
       "generation other renewable                     0.255601\n",
       "generation solar                               0.098572\n",
       "generation waste                               0.168825\n",
       "generation wind onshore                       -0.220444\n",
       "total load actual                              0.435660\n",
       "price day ahead                                0.732172\n",
       "y                                              1.000000\n",
       "lag1                                           0.966792\n",
       "lag2                                           0.900492\n",
       "lag4                                           0.744539\n",
       "rolling_mean_lag1_window_size4                 0.885148\n",
       "rolling_min_lag1_window_size4                  0.869544\n",
       "rolling_max_lag1_window_size4                  0.878464\n",
       "week                                           0.280829\n",
       "month                                          0.281345\n",
       "day                                            0.026931\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep.drop(columns=['unique_id', 'ds']).corr()['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fit method**\n",
    "\n",
    "Before we train the model, let’s create two lists with the names of the dynamic and static features.\n",
    "\n",
    "* `Dynamic features` are the ones that change over time. You need to have these values for the future timestamps you want to predict.\n",
    "* `Static features` are the ones that don’t change over time. MLForecast will repeat the first value of each static feature for all the timestamps you want to predict.\n",
    "\n",
    "For this example we have considered some variables such as `Static features` although they are not necessarily constant or static over time, but for the purpose of exemplifying how to add exogenous variables to our model it is a good way to exemplify the use of the `Dynamic features` variables such as those of the `Static features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_features = ['generation fossil brown coal/lignite','generation fossil gas','generation fossil hard coal','generation hydro pumped storage consumption',\n",
    "                    'generation hydro run-of-river and poundage','generation hydro water reservoir','generation solar','generation waste', \n",
    "                    'generation wind onshore', 'total load actual','price day ahead']\n",
    "\n",
    "static_features = ['generation biomass','generation fossil oil','generation nuclear','generation other','generation other renewable']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method uses the following parameters:\n",
    "|Parameters |Type\t|Default\t|Details|\n",
    "|-----------|-------|-----------|-------|\n",
    "|df|\tDataFrame|\t\t|Series data in long format.|\n",
    "|id_col|\tstr\t|unique_id|\tColumn that identifies each serie|.\n",
    "|time_col\t|str\t|ds\t|Column that identifies each timestep, its values can be timestamps or integers.\n",
    "|target_col\t|str\t|y\t|Column that contains the target.\n",
    "|static_features\t|typing.Optional[typing.List[str]]|\tNone\t|Names of the features that are static and will be repeated when forecasting. If None, will consider all columns (except id_col and time_col) as static.|\n",
    "|dropna\t|bool\t|True\t|Drop rows with missing values produced by the transformations.|\n",
    "|keep_last_n\t|typing.Optional[int]\t|None\t|Keep only these many records from each serie for the forecasting step. Can save time and memory if your features allow it.|\n",
    "|max_horizon\t|typing.Optional[int]\t|None\t|Train this many models, where each model will predict a specific horizon.|\n",
    "|prediction_intervals\t|typing.Optional[mlforecast.utils.PredictionIntervals]\t|None\t|Configuration to calibrate prediction intervals (Conformal Prediction).|\n",
    "|fitted\t|bool\t|False\t|Save in-sample predictions.|\n",
    "|data\t|typing.Optional[pandas.core.frame.DataFrame]\t|None\t|Series data in long format. This argument has been replaced by df and will be removed in a later release.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLForecast(models=[XGBRegressor], freq=<Hour>, lag_features=['lag1', 'lag2', 'lag4', 'rolling_mean_lag1_window_size4', 'rolling_min_lag1_window_size4', 'rolling_max_lag1_window_size4'], date_features=['week', 'month', 'day'], num_threads=6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlf.fit(df, fitted=True, static_features=static_features,  \n",
    "        prediction_intervals=PredictionIntervals(n_windows=5, window_size=30, method=\"conformal_distribution\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that when we use the fit method, we include the `static_features` parameter.\n",
    "\n",
    "- If you have no `static features`, pass an empty list or MLForecast will consider that all your additional columns are static.\n",
    "\n",
    "- By default the forecast is generated in a recursive way, but we can also use the `max_horizon` parameter to generate the forecast with the direct method (one model for each step ahead);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf.fit(df, static_features=static_features, max_horizon=30, fitted=True,\n",
    "        prediction_intervals=PredictionIntervals(n_windows=5, window_size=30, method=\"conformal_distribution\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When using the `max_horizon` parameter in the fit method, this may take more than 1 minute, which will depend on each team.\n",
    "\n",
    "* Let's see the results of our model in this case the `XGBoost model`. We can observe it with the following instruction:\n",
    "\n",
    "Let us now visualize the fitted values of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>56.04</td>\n",
       "      <td>56.156284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 05:00:00</td>\n",
       "      <td>53.63</td>\n",
       "      <td>53.193878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 06:00:00</td>\n",
       "      <td>51.73</td>\n",
       "      <td>51.625008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>51.43</td>\n",
       "      <td>51.410889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 08:00:00</td>\n",
       "      <td>48.98</td>\n",
       "      <td>51.442638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 19:00:00</td>\n",
       "      <td>77.02</td>\n",
       "      <td>78.329239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 20:00:00</td>\n",
       "      <td>76.16</td>\n",
       "      <td>76.288696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 21:00:00</td>\n",
       "      <td>74.30</td>\n",
       "      <td>73.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 22:00:00</td>\n",
       "      <td>69.89</td>\n",
       "      <td>71.720154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>69.88</td>\n",
       "      <td>69.092720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35060 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ds      y  XGBRegressor\n",
       "unique_id                                         \n",
       "1         2015-01-01 04:00:00  56.04     56.156284\n",
       "1         2015-01-01 05:00:00  53.63     53.193878\n",
       "1         2015-01-01 06:00:00  51.73     51.625008\n",
       "1         2015-01-01 07:00:00  51.43     51.410889\n",
       "1         2015-01-01 08:00:00  48.98     51.442638\n",
       "...                       ...    ...           ...\n",
       "1         2018-12-31 19:00:00  77.02     78.329239\n",
       "1         2018-12-31 20:00:00  76.16     76.288696\n",
       "1         2018-12-31 21:00:00  74.30     73.400200\n",
       "1         2018-12-31 22:00:00  69.89     71.720154\n",
       "1         2018-12-31 23:00:00  69.88     69.092720\n",
       "\n",
       "[35060 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=mlf.forecast_fitted_values()\n",
    "result=result.set_index(\"unique_id\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import normal_ad\n",
    "from scipy import stats\n",
    "\n",
    "sw_result = stats.shapiro(result[\"XGBRegressor\"])\n",
    "ad_result = normal_ad(np.array(result[\"XGBRegressor\"]), axis=0)\n",
    "dag_result = stats.normaltest(result[\"XGBRegressor\"], axis=0, nan_policy='propagate')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that we can only use this method if we assume that the residuals of our validation predictions are normally distributed. To see if this is the case, we will use a PP-plot and test its normality with the Anderson-Darling, Kolmogorov-Smirnov, and D’Agostino K^2 tests.\n",
    "\n",
    "The PP-plot(Probability-to-Probability) plots the data sample against the normal distribution plot in such a way that if normally distributed, the data points will form a straight line.\n",
    "\n",
    "The three normality tests determine how likely a data sample is from a normally distributed population using p-values. The null hypothesis for each test is that \"the sample came from a normally distributed population\". This means that if the resulting p-values are below a chosen alpha value, then the null hypothesis is rejected. Thus there is evidence to suggest that the data comes from a non-normal distribution. For this article, we will use an Alpha value of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=mlf.forecast_fitted_values()\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "# plot[1,1]\n",
    "result[\"XGBRegressor\"].plot(ax=axs[0,0])\n",
    "axs[0,0].set_title(\"Residuals model\");\n",
    "\n",
    "# plot\n",
    "#plot(result[\"XGBRegressor\"], ax=axs[0,1]);\n",
    "axs[0,1].hist(result[\"XGBRegressor\"], density=True,bins=50, alpha=0.5 )\n",
    "axs[0,1].set_title(\"Density plot - Residual\");\n",
    "\n",
    "# plot\n",
    "stats.probplot(result[\"XGBRegressor\"], dist=\"norm\", plot=axs[1,0])\n",
    "axs[1,0].set_title('Plot Q-Q')\n",
    "axs[1,0].annotate(\"SW p-val: {:.4f}\".format(sw_result[1]), xy=(0.05,0.9), xycoords='axes fraction', fontsize=15,\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
    "\n",
    "axs[1,0].annotate(\"AD p-val: {:.4f}\".format(ad_result[1]), xy=(0.05,0.8), xycoords='axes fraction', fontsize=15,\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
    "\n",
    "axs[1,0].annotate(\"DAG p-val: {:.4f}\".format(dag_result[1]), xy=(0.05,0.7), xycoords='axes fraction', fontsize=15,\n",
    "            bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
    "# plot\n",
    "plot_acf(result[\"XGBRegressor\"],  lags=35, ax=axs[1,1],color=\"fuchsia\")\n",
    "axs[1,1].set_title(\"Autocorrelation\");\n",
    "\n",
    "plt.savefig(\"../figs/multivariate_forecasting_and_prediction_intervals__plot_residual_model.png\")\n",
    "plt.close();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/multivariate_forecasting_and_prediction_intervals__plot_residual_model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predict method with prediction intervals**\n",
    "\n",
    "To generate forecasts use the predict method.\n",
    "\n",
    "The predict method takes several arguments.: \n",
    "\n",
    "|Parameters |Type\t|Default\t|Details|\n",
    "|-----------|-------|-----------|-------|\n",
    "|h\t|int\t|\t|Number of periods to predict.|\n",
    "|dynamic_dfs\t|typing.Optional[typing.List[pandas.core.frame.DataFrame]]\t|None\t|Future values of the dynamic features, e.g. prices.\n",
    "|before_predict_callback\t|typing.Optional[typing.Callable]\t|None\t|Function to call on the features before computing the predictions. This function will take the input dataframe that will be passed to the model for predicting and should return a dataframe with the same structure. The series identifier is on the index.\n",
    "|after_predict_callback\t|typing.Optional[typing.Callable]\t|None\t|Function to call on the predictions before updating the targets. This function will take a pandas Series with the predictions and should return another one with the same structure. The series identifier is on the index.\n",
    "|new_df\t|typing.Optional[pandas.core.frame.DataFrame]|\tNone\t|Series data of new observations for which forecasts are to be generated. This dataframe should have the same structure as the one used to fit the model, including any features and time series data. If new_df is not None, the method will generate forecasts for the new observations.\n",
    "|level\t|typing.Optional[typing.List[typing.Union[int, float]]]|\tNone\t|Confidence levels between 0 and 100 for prediction intervals.\n",
    "|X_df\t|typing.Optional[pandas.core.frame.DataFrame]\t|None\t|Dataframe with the future exogenous features. Should have the id column and the time column.\n",
    "|ids\t|typing.Optional[typing.List[str]]\t|None\t|List with subset of ids seen during training for which the forecasts should be computed.\n",
    "|horizon\t|typing.Optional[int]|\tNone\t|Number of periods to predict. This argument has been replaced by h and will be removed in a later release.\n",
    "|new_data\t|typing.Optional[pandas.core.frame.DataFrame]\t|None\t|Series data of new observations for which forecasts are to be generated. This dataframe should have the same structure as the one used to fit the model, including any features and time series data. If new_data is not None, the method will generate forecasts for the new observation\n",
    "\n",
    "\n",
    "\n",
    "The forecast object here is a new data frame that includes a column with the name of the model and the y hat values, as well as columns for the uncertainty intervals.\n",
    "\n",
    "This step should take less than 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>XGBRegressor-lo-95</th>\n",
       "      <th>XGBRegressor-lo-80</th>\n",
       "      <th>XGBRegressor-hi-80</th>\n",
       "      <th>XGBRegressor-hi-95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>67.201607</td>\n",
       "      <td>66.026950</td>\n",
       "      <td>66.427206</td>\n",
       "      <td>67.976008</td>\n",
       "      <td>68.376263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>64.311119</td>\n",
       "      <td>62.169308</td>\n",
       "      <td>62.311854</td>\n",
       "      <td>66.310384</td>\n",
       "      <td>66.452930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>63.003006</td>\n",
       "      <td>60.632687</td>\n",
       "      <td>60.703998</td>\n",
       "      <td>65.302014</td>\n",
       "      <td>65.373325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>61.003784</td>\n",
       "      <td>58.959198</td>\n",
       "      <td>59.253872</td>\n",
       "      <td>62.753696</td>\n",
       "      <td>63.048370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>60.615204</td>\n",
       "      <td>58.270322</td>\n",
       "      <td>58.458266</td>\n",
       "      <td>62.772141</td>\n",
       "      <td>62.960086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 05:00:00</td>\n",
       "      <td>61.224861</td>\n",
       "      <td>58.845230</td>\n",
       "      <td>59.680048</td>\n",
       "      <td>62.769674</td>\n",
       "      <td>63.604492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>62.603184</td>\n",
       "      <td>61.060147</td>\n",
       "      <td>61.498018</td>\n",
       "      <td>63.708350</td>\n",
       "      <td>64.146221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 07:00:00</td>\n",
       "      <td>65.311356</td>\n",
       "      <td>58.622908</td>\n",
       "      <td>61.759400</td>\n",
       "      <td>68.863311</td>\n",
       "      <td>71.999803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 08:00:00</td>\n",
       "      <td>69.205391</td>\n",
       "      <td>65.525402</td>\n",
       "      <td>66.567001</td>\n",
       "      <td>71.843781</td>\n",
       "      <td>72.885379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>71.437088</td>\n",
       "      <td>69.869902</td>\n",
       "      <td>70.025982</td>\n",
       "      <td>72.848194</td>\n",
       "      <td>73.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 10:00:00</td>\n",
       "      <td>71.636887</td>\n",
       "      <td>69.903017</td>\n",
       "      <td>70.288947</td>\n",
       "      <td>72.984827</td>\n",
       "      <td>73.370756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>71.521896</td>\n",
       "      <td>69.907379</td>\n",
       "      <td>70.151964</td>\n",
       "      <td>72.891829</td>\n",
       "      <td>73.136413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 12:00:00</td>\n",
       "      <td>70.905952</td>\n",
       "      <td>68.963730</td>\n",
       "      <td>69.222705</td>\n",
       "      <td>72.589200</td>\n",
       "      <td>72.848175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 13:00:00</td>\n",
       "      <td>69.662575</td>\n",
       "      <td>65.423166</td>\n",
       "      <td>68.275356</td>\n",
       "      <td>71.049793</td>\n",
       "      <td>73.901983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 14:00:00</td>\n",
       "      <td>69.795380</td>\n",
       "      <td>66.804315</td>\n",
       "      <td>67.686521</td>\n",
       "      <td>71.904238</td>\n",
       "      <td>72.786445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 15:00:00</td>\n",
       "      <td>70.211876</td>\n",
       "      <td>69.229773</td>\n",
       "      <td>69.837295</td>\n",
       "      <td>70.586457</td>\n",
       "      <td>71.193979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 16:00:00</td>\n",
       "      <td>69.892937</td>\n",
       "      <td>66.656021</td>\n",
       "      <td>67.223393</td>\n",
       "      <td>72.562480</td>\n",
       "      <td>73.129852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 17:00:00</td>\n",
       "      <td>69.168762</td>\n",
       "      <td>64.680314</td>\n",
       "      <td>67.374402</td>\n",
       "      <td>70.963122</td>\n",
       "      <td>73.657210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 18:00:00</td>\n",
       "      <td>68.030434</td>\n",
       "      <td>63.315460</td>\n",
       "      <td>64.625359</td>\n",
       "      <td>71.435508</td>\n",
       "      <td>72.745407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 19:00:00</td>\n",
       "      <td>67.345955</td>\n",
       "      <td>62.304418</td>\n",
       "      <td>64.679146</td>\n",
       "      <td>70.012764</td>\n",
       "      <td>72.387492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 20:00:00</td>\n",
       "      <td>66.105659</td>\n",
       "      <td>57.378027</td>\n",
       "      <td>63.092576</td>\n",
       "      <td>69.118743</td>\n",
       "      <td>74.833292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 21:00:00</td>\n",
       "      <td>64.167175</td>\n",
       "      <td>52.250720</td>\n",
       "      <td>60.815607</td>\n",
       "      <td>67.518744</td>\n",
       "      <td>76.083630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 22:00:00</td>\n",
       "      <td>64.890800</td>\n",
       "      <td>55.135071</td>\n",
       "      <td>60.635374</td>\n",
       "      <td>69.146227</td>\n",
       "      <td>74.646530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 23:00:00</td>\n",
       "      <td>67.534096</td>\n",
       "      <td>62.139078</td>\n",
       "      <td>62.311623</td>\n",
       "      <td>72.756568</td>\n",
       "      <td>72.929113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02 00:00:00</td>\n",
       "      <td>70.925293</td>\n",
       "      <td>66.375517</td>\n",
       "      <td>67.467046</td>\n",
       "      <td>74.383540</td>\n",
       "      <td>75.475069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02 01:00:00</td>\n",
       "      <td>71.965919</td>\n",
       "      <td>69.463209</td>\n",
       "      <td>69.612321</td>\n",
       "      <td>74.319518</td>\n",
       "      <td>74.468630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02 02:00:00</td>\n",
       "      <td>72.389908</td>\n",
       "      <td>70.472733</td>\n",
       "      <td>70.876404</td>\n",
       "      <td>73.903412</td>\n",
       "      <td>74.307083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02 03:00:00</td>\n",
       "      <td>72.576996</td>\n",
       "      <td>70.096813</td>\n",
       "      <td>70.263418</td>\n",
       "      <td>74.890574</td>\n",
       "      <td>75.057179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02 04:00:00</td>\n",
       "      <td>72.575966</td>\n",
       "      <td>70.036650</td>\n",
       "      <td>70.570591</td>\n",
       "      <td>74.581341</td>\n",
       "      <td>75.115281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-02 05:00:00</td>\n",
       "      <td>72.575966</td>\n",
       "      <td>69.338382</td>\n",
       "      <td>70.343427</td>\n",
       "      <td>74.808505</td>\n",
       "      <td>75.813550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id                  ds  XGBRegressor  XGBRegressor-lo-95  \\\n",
       "0          1 2019-01-01 00:00:00     67.201607           66.026950   \n",
       "1          1 2019-01-01 01:00:00     64.311119           62.169308   \n",
       "2          1 2019-01-01 02:00:00     63.003006           60.632687   \n",
       "3          1 2019-01-01 03:00:00     61.003784           58.959198   \n",
       "4          1 2019-01-01 04:00:00     60.615204           58.270322   \n",
       "5          1 2019-01-01 05:00:00     61.224861           58.845230   \n",
       "6          1 2019-01-01 06:00:00     62.603184           61.060147   \n",
       "7          1 2019-01-01 07:00:00     65.311356           58.622908   \n",
       "8          1 2019-01-01 08:00:00     69.205391           65.525402   \n",
       "9          1 2019-01-01 09:00:00     71.437088           69.869902   \n",
       "10         1 2019-01-01 10:00:00     71.636887           69.903017   \n",
       "11         1 2019-01-01 11:00:00     71.521896           69.907379   \n",
       "12         1 2019-01-01 12:00:00     70.905952           68.963730   \n",
       "13         1 2019-01-01 13:00:00     69.662575           65.423166   \n",
       "14         1 2019-01-01 14:00:00     69.795380           66.804315   \n",
       "15         1 2019-01-01 15:00:00     70.211876           69.229773   \n",
       "16         1 2019-01-01 16:00:00     69.892937           66.656021   \n",
       "17         1 2019-01-01 17:00:00     69.168762           64.680314   \n",
       "18         1 2019-01-01 18:00:00     68.030434           63.315460   \n",
       "19         1 2019-01-01 19:00:00     67.345955           62.304418   \n",
       "20         1 2019-01-01 20:00:00     66.105659           57.378027   \n",
       "21         1 2019-01-01 21:00:00     64.167175           52.250720   \n",
       "22         1 2019-01-01 22:00:00     64.890800           55.135071   \n",
       "23         1 2019-01-01 23:00:00     67.534096           62.139078   \n",
       "24         1 2019-01-02 00:00:00     70.925293           66.375517   \n",
       "25         1 2019-01-02 01:00:00     71.965919           69.463209   \n",
       "26         1 2019-01-02 02:00:00     72.389908           70.472733   \n",
       "27         1 2019-01-02 03:00:00     72.576996           70.096813   \n",
       "28         1 2019-01-02 04:00:00     72.575966           70.036650   \n",
       "29         1 2019-01-02 05:00:00     72.575966           69.338382   \n",
       "\n",
       "    XGBRegressor-lo-80  XGBRegressor-hi-80  XGBRegressor-hi-95  \n",
       "0            66.427206           67.976008           68.376263  \n",
       "1            62.311854           66.310384           66.452930  \n",
       "2            60.703998           65.302014           65.373325  \n",
       "3            59.253872           62.753696           63.048370  \n",
       "4            58.458266           62.772141           62.960086  \n",
       "5            59.680048           62.769674           63.604492  \n",
       "6            61.498018           63.708350           64.146221  \n",
       "7            61.759400           68.863311           71.999803  \n",
       "8            66.567001           71.843781           72.885379  \n",
       "9            70.025982           72.848194           73.004274  \n",
       "10           70.288947           72.984827           73.370756  \n",
       "11           70.151964           72.891829           73.136413  \n",
       "12           69.222705           72.589200           72.848175  \n",
       "13           68.275356           71.049793           73.901983  \n",
       "14           67.686521           71.904238           72.786445  \n",
       "15           69.837295           70.586457           71.193979  \n",
       "16           67.223393           72.562480           73.129852  \n",
       "17           67.374402           70.963122           73.657210  \n",
       "18           64.625359           71.435508           72.745407  \n",
       "19           64.679146           70.012764           72.387492  \n",
       "20           63.092576           69.118743           74.833292  \n",
       "21           60.815607           67.518744           76.083630  \n",
       "22           60.635374           69.146227           74.646530  \n",
       "23           62.311623           72.756568           72.929113  \n",
       "24           67.467046           74.383540           75.475069  \n",
       "25           69.612321           74.319518           74.468630  \n",
       "26           70.876404           73.903412           74.307083  \n",
       "27           70.263418           74.890574           75.057179  \n",
       "28           70.570591           74.581341           75.115281  \n",
       "29           70.343427           74.808505           75.813550  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df =mlf.predict(horizon=30,level=[80,95],dynamic_dfs=[df[['unique_id','ds']+dynamic_features]])\n",
    "forecast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_series(df, forecast_df, level=[80,95], max_insample_length=200,engine=\"matplotlib\", palette=\"magma\")\n",
    "fig.get_axes()[0].set_title(\"Prediction with intervals\")\n",
    "fig.savefig('../figs/multivariate_forecasting_and_prediction_intervals__plot_forecasting_intervals.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/multivariate_forecasting_and_prediction_intervals__plot_forecasting_intervals.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature importances** <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "[Table of Contents](#0)\n",
    "\n",
    "Take a look at the feature importances too.\n",
    "\n",
    "This model is heavily dependent on the lag 1 feature, as you can see in the feature importance plot for XGBRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=pd.Series(mlf.models_['XGBRegressor'].feature_importances_, \n",
    "              index=mlf.ts.features_order_).sort_values(ascending=False).plot.bar(title='Feature Importance XGBRegressor')\n",
    "plt.savefig('../figs/multivariate_forecasting_and_prediction_intervals__plot_feature_importance.png',dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../figs/multivariate_forecasting_and_prediction_intervals__plot_feature_importance.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluate the model’s performance** <a class=\"anchor\" id=\"6\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "In previous steps, we’ve taken our historical data to predict the future. However, to asses its accuracy we would also like to know how the model would have performed in the past. To assess the accuracy and robustness of your models on your data perform Cross-Validation.\n",
    "\n",
    "With time series data, Cross Validation is done by defining a sliding window across the historical data and predicting the period following it. This form of cross-validation allows us to arrive at a better estimation of our model’s predictive abilities across a wider range of temporal instances while also keeping the data in the training set contiguous as is required by our models.\n",
    "\n",
    "The following graph depicts such a Cross Validation Strategy:\n",
    "\n",
    "![](https://raw.githubusercontent.com/Nixtla/statsforecast/main/nbs/imgs/ChainedWindows.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Perform time series cross-validation**\n",
    "\n",
    "In order to get an estimate of how well our model will be when predicting future data we can perform cross validation, which consist on training a few models independently on different subsets of the data, using them to predict a validation set and measuring their performance.\n",
    "\n",
    "Since our data depends on time, we make our splits by removing the last portions of the series and using them as validation sets. This process is implemented in `MLForecast.cross_validation`.\n",
    "\n",
    "Cross-validation of time series models is considered a best practice but most implementations are very slow. The `MlForecast` library implements cross-validation as a distributed operation, making the process less time-consuming to perform. If you have big datasets you can also perform Cross Validation in a distributed cluster using `Ray, Dask or Spark`.\n",
    "\n",
    "Depending on your computer, this step should take around 1 min.\n",
    "\n",
    "The cross_validation method from the StatsForecast class takes the following arguments.\n",
    "\n",
    "* `df:` training data frame\n",
    "\n",
    "* `h (int):` represents h steps into the future that are being forecasted. In this case, 12 months ahead.\n",
    "\n",
    "* `step_size (int):` step size between each window. In other words: how often do you want to run the forecasting processes.\n",
    "\n",
    "* `n_windows(int):` number of windows used for cross validation. In other words: what number of forecasting processes in the past do you want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = mlf.cross_validation(\n",
    "    df,\n",
    "    n_windows=5,  # number of models to train/splits to perform\n",
    "    window_size=30,  # length of the validation set in each window\n",
    "    static_features=static_features,\n",
    "    prediction_intervals=PredictionIntervals(n_windows=5, window_size=30, method=\"conformal_distribution\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crossvaldation_df object is a new data frame that includes the following columns:\n",
    "\n",
    "* `unique_id:` index. If you dont like working with index just run `crossvalidation_df.resetindex()`.\n",
    "* `ds:` datestamp or temporal index\n",
    "* `cutoff:` the last datestamp or temporal index for the `n_windows`.\n",
    "* `y:` true value\n",
    "* `model:` columns with the model’s name and fitted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>y</th>\n",
       "      <th>XGBRegressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-25 18:00:00</td>\n",
       "      <td>2018-12-25 17:00:00</td>\n",
       "      <td>71.73</td>\n",
       "      <td>72.156570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-25 19:00:00</td>\n",
       "      <td>2018-12-25 17:00:00</td>\n",
       "      <td>71.94</td>\n",
       "      <td>73.250244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-25 20:00:00</td>\n",
       "      <td>2018-12-25 17:00:00</td>\n",
       "      <td>73.05</td>\n",
       "      <td>73.350319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-25 21:00:00</td>\n",
       "      <td>2018-12-25 17:00:00</td>\n",
       "      <td>73.94</td>\n",
       "      <td>74.397888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-25 22:00:00</td>\n",
       "      <td>2018-12-25 17:00:00</td>\n",
       "      <td>71.98</td>\n",
       "      <td>73.627937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31 19:00:00</td>\n",
       "      <td>2018-12-30 17:00:00</td>\n",
       "      <td>77.02</td>\n",
       "      <td>73.463821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31 20:00:00</td>\n",
       "      <td>2018-12-30 17:00:00</td>\n",
       "      <td>76.16</td>\n",
       "      <td>72.620155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31 21:00:00</td>\n",
       "      <td>2018-12-30 17:00:00</td>\n",
       "      <td>74.30</td>\n",
       "      <td>71.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31 22:00:00</td>\n",
       "      <td>2018-12-30 17:00:00</td>\n",
       "      <td>69.89</td>\n",
       "      <td>69.561783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>2018-12-30 17:00:00</td>\n",
       "      <td>69.88</td>\n",
       "      <td>68.188576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id                  ds              cutoff      y  XGBRegressor\n",
       "0          1 2018-12-25 18:00:00 2018-12-25 17:00:00  71.73     72.156570\n",
       "1          1 2018-12-25 19:00:00 2018-12-25 17:00:00  71.94     73.250244\n",
       "2          1 2018-12-25 20:00:00 2018-12-25 17:00:00  73.05     73.350319\n",
       "3          1 2018-12-25 21:00:00 2018-12-25 17:00:00  73.94     74.397888\n",
       "4          1 2018-12-25 22:00:00 2018-12-25 17:00:00  71.98     73.627937\n",
       "..       ...                 ...                 ...    ...           ...\n",
       "25         1 2018-12-31 19:00:00 2018-12-30 17:00:00  77.02     73.463821\n",
       "26         1 2018-12-31 20:00:00 2018-12-30 17:00:00  76.16     72.620155\n",
       "27         1 2018-12-31 21:00:00 2018-12-30 17:00:00  74.30     71.002312\n",
       "28         1 2018-12-31 22:00:00 2018-12-30 17:00:00  69.89     69.561783\n",
       "29         1 2018-12-31 23:00:00 2018-12-30 17:00:00  69.88     68.188576\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluate the model** <a class=\"anchor\" id=\"7\"></a>\n",
    "\n",
    "[Table of Contents](#0.1)\n",
    "\n",
    "We can now compute the accuracy of the forecast using an appropiate accuracy metric. Here we’ll use the Root Mean Squared Error (RMSE). To do this, we first need to `install datasetsforecast`, a Python library developed **by Nixtla** that includes a function to compute the RMSE.\n",
    "\n",
    "`pip install datasetsforecast`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.losses import rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to compute the RMSE takes two arguments:\n",
    "\n",
    "1. The actual values.\n",
    "2. The forecasts, in this case, `XGBRegressor() Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.losses import mse, mae, rmse\n",
    "\n",
    "def evaluate_cross_validation(df, metric):\n",
    "    models = df.drop(columns=['ds', 'cutoff', 'y']).columns.tolist()\n",
    "    evals = []\n",
    "    for model in models:\n",
    "        eval_ = df.groupby(['unique_id', 'cutoff']).apply(lambda x: metric(x['y'].values, x[model].values)).to_frame() # Calculate loss for every unique_id, model and cutoff.\n",
    "        eval_.columns = [model]\n",
    "        evals.append(eval_)\n",
    "    evals = pd.concat(evals, axis=1)\n",
    "    evals = evals.groupby(['unique_id']).mean(numeric_only=True) # Averages the error metrics for all cutoffs for every combination of model and unique_id\n",
    "    evals['best_model'] = evals.idxmin(axis=1)\n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBRegressor</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.81789</td>\n",
       "      <td>XGBRegressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           XGBRegressor    best_model\n",
       "unique_id                            \n",
       "1               1.81789  XGBRegressor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df = evaluate_cross_validation(cv_result.set_index(\"unique_id\"), rmse)\n",
    "\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using cross-validation:  1.81789025583616\n"
     ]
    }
   ],
   "source": [
    "cv_rmse = cv_result.groupby(['unique_id', 'cutoff']).apply(lambda df: rmse(df['y'], df['XGBRegressor'])).mean()\n",
    "print(\"RMSE using cross-validation: \", cv_rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **References** <a class=\"anchor\" id=\"8\"></a>\n",
    "\n",
    "[Table of Contents](#0)\n",
    "\n",
    "\n",
    "1. Changquan Huang • Alla Petukhina. Springer series (2022). Applied Time Series Analysis and Forecasting with Python. \n",
    "2. Ivan Svetunkov. [Forecasting and Analytics with the Augmented Dynamic Adaptive Model (ADAM)](https://openforecast.org/adam/)\n",
    "3. [James D. Hamilton. Time Series Analysis Princeton University Press, Princeton, New Jersey, 1st Edition, 1994.](https://press.princeton.edu/books/hardcover/9780691042893/time-series-analysis)\n",
    "4. [Nixtla Parameters for Mlforecast](https://nixtla.github.io/mlforecast/forecast.html).\n",
    "5. [Pandas available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).\n",
    "6. [Rob J. Hyndman and George Athanasopoulos (2018). “Forecasting principles and practice, Time series cross-validation”.](https://otexts.com/fpp3/tscv.html).\n",
    "7. [Seasonal periods- Rob J Hyndman](https://robjhyndman.com/hyndsight/seasonal-periods/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
